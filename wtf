diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index e4b1e74ca..f8f4948db 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -393,6 +393,27 @@ jobs:
         env:
           RELAY_VERSION_CHAIN: "20.6.0,latest"
 
+  rust_integration_tests:
+    name: Rust Integration Tests
+    runs-on: ubuntu-latest
+    timeout-minutes: 20
+
+    steps:
+      - name: Checkout code
+        uses: actions/checkout@v4
+        with:
+          submodules: recursive
+
+      - name: Install Rust Toolchain
+        run: rustup toolchain install stable --profile minimal --no-self-update
+
+      - uses: swatinem/rust-cache@v2
+        with:
+          key: ${{ github.job }}
+
+      - name: Run Rust Integration Tests
+        run: cargo test
+
   sentry-relay-integration-tests:
     name: Sentry-Relay Integration Tests
     runs-on: ubuntu-latest
diff --git a/Cargo.lock b/Cargo.lock
index 5926c30ae..55e1ac726 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -23,7 +23,7 @@ version = "0.7.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fcb51a0695d8f838b1ee009b3fbf66bda078cd64590202a864a8f3e8c4315c47"
 dependencies = [
- "getrandom",
+ "getrandom 0.2.8",
  "once_cell",
  "version_check",
 ]
@@ -35,7 +35,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "42cd52102d3df161c77a887b608d7a4897d7cc112886a9537b738a887a03aaff"
 dependencies = [
  "cfg-if",
- "getrandom",
+ "getrandom 0.2.8",
  "once_cell",
  "serde",
  "version_check",
@@ -249,7 +249,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "edcdbedc2236483ab103a53415653d6b4442ea6141baf1ffa85df29635e88436"
 dependencies = [
  "nix",
- "rand",
+ "rand 0.8.5",
 ]
 
 [[package]]
@@ -370,9 +370,9 @@ version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b62ddb9cb1ec0a098ad4bbf9344d0713fa193ae1a80af55febcff2627b6a00c1"
 dependencies = [
- "getrandom",
+ "getrandom 0.2.8",
  "instant",
- "rand",
+ "rand 0.8.5",
 ]
 
 [[package]]
@@ -601,8 +601,10 @@ checksum = "7f2c685bad3eb3d45a01354cedb7d5faa66194d1d58ba6e267a8de788f79db38"
 dependencies = [
  "android-tzdata",
  "iana-time-zone",
+ "js-sys",
  "num-traits",
  "serde",
+ "wasm-bindgen",
  "windows-targets 0.48.5",
 ]
 
@@ -758,6 +760,17 @@ version = "0.9.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "520fbf3c07483f94e3e3ca9d0cfd913d7718ef2483d2cfd91c0d9e91474ab913"
 
+[[package]]
+name = "contracts"
+version = "0.4.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "c9424f2ca1e42776615720e5746eed6efa19866fdbaac2923ab51c294ac4d1f2"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "syn 1.0.109",
+]
+
 [[package]]
 name = "convert_case"
 version = "0.4.0"
@@ -1173,7 +1186,7 @@ checksum = "7277392b266383ef8396db7fdeb1e77b6c52fed775f5df15bb24f35b72156980"
 dependencies = [
  "curve25519-dalek",
  "ed25519",
- "rand_core",
+ "rand_core 0.6.4",
  "serde",
  "sha2",
  "zeroize",
@@ -1337,12 +1350,12 @@ dependencies = [
 
 [[package]]
 name = "errno"
-version = "0.3.5"
+version = "0.3.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ac3e13f66a2f95e32a39eaa81f6b95d42878ca0e1db0c7543723dfe12557e860"
+checksum = "a258e46cdc063eb8519c00b9fc845fc47bcfca4130e2f08e88665ceda8474245"
 dependencies = [
  "libc",
- "windows-sys 0.48.0",
+ "windows-sys 0.52.0",
 ]
 
 [[package]]
@@ -1374,12 +1387,9 @@ dependencies = [
 
 [[package]]
 name = "fastrand"
-version = "1.8.0"
+version = "2.0.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a7a407cfaa3385c4ae6b23e84623d48c2798d06e3e6a1878f7f59f17b3f86499"
-dependencies = [
- "instant",
-]
+checksum = "25cbce373ec4653f1a01a31e8a5e5ec0c622dc27ff9c4e6606eefef5cbbed4a5"
 
 [[package]]
 name = "fiat-crypto"
@@ -1580,6 +1590,17 @@ dependencies = [
  "version_check",
 ]
 
+[[package]]
+name = "getrandom"
+version = "0.1.16"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8fc3cb4d91f53b50155bdcfd23f6a4c39ae1969c2ae85982b135750cccaf5fce"
+dependencies = [
+ "cfg-if",
+ "libc",
+ "wasi 0.9.0+wasi-snapshot-preview1",
+]
+
 [[package]]
 name = "getrandom"
 version = "0.2.8"
@@ -1589,7 +1610,7 @@ dependencies = [
  "cfg-if",
  "js-sys",
  "libc",
- "wasi",
+ "wasi 0.11.0+wasi-snapshot-preview1",
  "wasm-bindgen",
 ]
 
@@ -2222,17 +2243,6 @@ dependencies = [
  "web-sys",
 ]
 
-[[package]]
-name = "io-lifetimes"
-version = "1.0.11"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "eae7b9aee968036d54dce06cebaefd919e4472e753296daccd6d344e3e2df0c2"
-dependencies = [
- "hermit-abi 0.3.1",
- "libc",
- "windows-sys 0.48.0",
-]
-
 [[package]]
 name = "ipconfig"
 version = "0.3.1"
@@ -2276,7 +2286,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "cb0889898416213fab133e1d33a0e5858a48177452750691bde3666d0fdbaf8b"
 dependencies = [
  "hermit-abi 0.3.1",
- "rustix 0.38.20",
+ "rustix",
  "windows-sys 0.48.0",
 ]
 
@@ -2341,7 +2351,7 @@ dependencies = [
  "clap",
  "fancy-regex",
  "fraction",
- "getrandom",
+ "getrandom 0.2.8",
  "iso8601",
  "itoa",
  "memchr",
@@ -2375,9 +2385,9 @@ checksum = "830d08ce1d1d941e6b30645f1a0eb5643013d835ce3779a5fc208261dbe10f55"
 
 [[package]]
 name = "libc"
-version = "0.2.149"
+version = "0.2.153"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a08173bc88b7955d1b3145aa561539096c421ac8debde8cbc3612ec635fee29b"
+checksum = "9c198f91728a82281a64e1f4f9eeb25d82cb32a5de251c6bd1b5154d63a8e7bd"
 
 [[package]]
 name = "libloading"
@@ -2435,15 +2445,9 @@ checksum = "0717cef1bc8b636c6e1c1bbdefc09e6322da8a9321966e8928ef80d20f7f770f"
 
 [[package]]
 name = "linux-raw-sys"
-version = "0.3.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b64f40e5e03e0d54f03845c8197d0291253cdbedfb1cb46b13c2c117554a9f4c"
-
-[[package]]
-name = "linux-raw-sys"
-version = "0.4.10"
+version = "0.4.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "da2479e8c062e40bf0066ffa0bc823de0a9368974af99c9f6df941d2c231e03f"
+checksum = "01cda141df6706de531b6c46c3a33ecca755538219bd484262fa09410c13539c"
 
 [[package]]
 name = "lock_api"
@@ -2633,7 +2637,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "927a765cd3fc26206e66b296465fa9d3e5ab003e651c1b3c060e7956d96b19d2"
 dependencies = [
  "libc",
- "wasi",
+ "wasi 0.11.0+wasi-snapshot-preview1",
  "windows-sys 0.48.0",
 ]
 
@@ -2690,6 +2694,16 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "no_deadlocks"
+version = "1.3.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e0e0af0e4fcf0d695f224cafbf5e4fb750b85aa1cd1ad0b37d8d0d98c0d2ce5e"
+dependencies = [
+ "backtrace",
+ "vector-map",
+]
+
 [[package]]
 name = "nom"
 version = "7.1.3"
@@ -2756,7 +2770,7 @@ dependencies = [
  "num-integer",
  "num-iter",
  "num-traits",
- "rand",
+ "rand 0.8.5",
  "smallvec",
  "zeroize",
 ]
@@ -2967,7 +2981,7 @@ dependencies = [
  "opentelemetry",
  "ordered-float",
  "percent-encoding",
- "rand",
+ "rand 0.8.5",
  "thiserror",
 ]
 
@@ -3015,7 +3029,7 @@ checksum = "9069cbb9f99e3a5083476ccb29ceb1de18b9118cafa53e90c9551235de2b9521"
 dependencies = [
  "cfg-if",
  "libc",
- "redox_syscall 0.2.16",
+ "redox_syscall",
  "smallvec",
  "windows-sys 0.45.0",
 ]
@@ -3360,6 +3374,19 @@ dependencies = [
  "scheduled-thread-pool",
 ]
 
+[[package]]
+name = "rand"
+version = "0.7.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "6a6b1679d49b24bbfe0c803429aa1874472f50d9b363131f0e89fc356b544d03"
+dependencies = [
+ "getrandom 0.1.16",
+ "libc",
+ "rand_chacha 0.2.2",
+ "rand_core 0.5.1",
+ "rand_hc",
+]
+
 [[package]]
 name = "rand"
 version = "0.8.5"
@@ -3367,8 +3394,18 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "34af8d1a0e25924bc5b7c43c079c942339d8f0a8b57c39049bef581b46327404"
 dependencies = [
  "libc",
- "rand_chacha",
- "rand_core",
+ "rand_chacha 0.3.1",
+ "rand_core 0.6.4",
+]
+
+[[package]]
+name = "rand_chacha"
+version = "0.2.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "f4c8ed856279c9737206bf725bf36935d8666ead7aa69b52be55af369d193402"
+dependencies = [
+ "ppv-lite86",
+ "rand_core 0.5.1",
 ]
 
 [[package]]
@@ -3378,7 +3415,16 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e6c10a63a0fa32252be49d21e7709d4d4baf8d231c2dbce1eaa8141b9b127d88"
 dependencies = [
  "ppv-lite86",
- "rand_core",
+ "rand_core 0.6.4",
+]
+
+[[package]]
+name = "rand_core"
+version = "0.5.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "90bde5296fc891b0cef12a6d03ddccc162ce7b2aff54160af9338f8d40df6d19"
+dependencies = [
+ "getrandom 0.1.16",
 ]
 
 [[package]]
@@ -3387,7 +3433,16 @@ version = "0.6.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "ec0be4795e2f6a28069bec0b5ff3e2ac9bafc99e6a9a7dc3547996c5c816922c"
 dependencies = [
- "getrandom",
+ "getrandom 0.2.8",
+]
+
+[[package]]
+name = "rand_hc"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "ca3129af7b92a17112d59ad498c6f81eaf463253766b90396d39ea7a39d6613c"
+dependencies = [
+ "rand_core 0.5.1",
 ]
 
 [[package]]
@@ -3396,7 +3451,7 @@ version = "0.3.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "59cad018caf63deb318e5a4586d99a24424a364f40f1e5778c29aca23f4fc73e"
 dependencies = [
- "rand_core",
+ "rand_core 0.6.4",
 ]
 
 [[package]]
@@ -3474,7 +3529,7 @@ dependencies = [
  "native-tls",
  "percent-encoding",
  "r2d2",
- "rand",
+ "rand 0.8.5",
  "ryu",
  "sha1_smol",
  "socket2 0.4.9",
@@ -3490,15 +3545,6 @@ dependencies = [
  "bitflags 1.3.2",
 ]
 
-[[package]]
-name = "redox_syscall"
-version = "0.3.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "567664f262709473930a4bf9e51bf2ebf3348f2e748ccc50dea20646858f8f29"
-dependencies = [
- "bitflags 1.3.2",
-]
-
 [[package]]
 name = "regex"
 version = "1.10.2"
@@ -3553,10 +3599,15 @@ dependencies = [
  "dialoguer",
  "hostname",
  "once_cell",
+ "relay-base-schema",
  "relay-config",
+ "relay-event-schema",
  "relay-log",
+ "relay-sampling",
  "relay-server",
  "relay-statsd",
+ "relay-test",
+ "serde_json",
  "tikv-jemallocator",
  "uuid",
 ]
@@ -3569,7 +3620,7 @@ dependencies = [
  "data-encoding",
  "ed25519-dalek",
  "hmac",
- "rand",
+ "rand 0.8.5",
  "relay-common",
  "serde",
  "serde_json",
@@ -3890,7 +3941,7 @@ dependencies = [
  "hashbrown 0.14.3",
  "insta",
  "itertools",
- "rand",
+ "rand 0.8.5",
  "relay-base-schema",
  "relay-cardinality",
  "relay-common",
@@ -4049,7 +4100,7 @@ dependencies = [
  "anyhow",
  "chrono",
  "insta",
- "rand",
+ "rand 0.8.5",
  "rand_pcg",
  "relay-base-schema",
  "relay-common",
@@ -4090,7 +4141,7 @@ dependencies = [
  "minidump",
  "multer",
  "once_cell",
- "rand",
+ "rand 0.8.5",
  "regex",
  "relay-auth",
  "relay-aws-extension",
@@ -4161,7 +4212,7 @@ dependencies = [
  "cadence",
  "crossbeam-channel",
  "parking_lot",
- "rand",
+ "rand 0.8.5",
  "relay-log",
 ]
 
@@ -4180,9 +4231,32 @@ dependencies = [
 name = "relay-test"
 version = "24.2.0"
 dependencies = [
+ "axum",
+ "axum-server",
+ "chrono",
+ "flate2",
+ "hyper",
+ "lazy_static",
+ "no_deadlocks",
+ "relay-auth",
+ "relay-base-schema",
+ "relay-common",
+ "relay-config",
+ "relay-dynamic-config",
+ "relay-event-schema",
  "relay-log",
+ "relay-protocol",
+ "relay-quotas",
+ "relay-sampling",
+ "relay-server",
  "relay-system",
+ "reqwest",
+ "serde",
+ "serde_json",
+ "serde_yaml 0.9.17",
+ "tempfile",
  "tokio",
+ "uuid",
 ]
 
 [[package]]
@@ -4307,7 +4381,7 @@ dependencies = [
  "num-traits",
  "pkcs1",
  "pkcs8",
- "rand_core",
+ "rand_core 0.6.4",
  "signature",
  "spki",
  "subtle",
@@ -4371,29 +4445,15 @@ dependencies = [
 
 [[package]]
 name = "rustix"
-version = "0.37.25"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d4eb579851244c2c03e7c24f501c3432bed80b8f720af1d6e5b0e0f01555a035"
-dependencies = [
- "bitflags 1.3.2",
- "errno",
- "io-lifetimes",
- "libc",
- "linux-raw-sys 0.3.6",
- "windows-sys 0.48.0",
-]
-
-[[package]]
-name = "rustix"
-version = "0.38.20"
+version = "0.38.31"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "67ce50cb2e16c2903e30d1cbccfd8387a74b9d4c938b6a4c5ec6cc7556f7a8a0"
+checksum = "6ea3e1a662af26cd7a3ba09c0297a31af215563ecf42817c98df621387f4e949"
 dependencies = [
  "bitflags 2.4.1",
  "errno",
  "libc",
- "linux-raw-sys 0.4.10",
- "windows-sys 0.48.0",
+ "linux-raw-sys",
+ "windows-sys 0.52.0",
 ]
 
 [[package]]
@@ -4585,7 +4645,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8f51264e4013ed9b16558cce43917b983fa38170de2ca480349ceb57d71d6053"
 dependencies = [
  "once_cell",
- "rand",
+ "rand 0.8.5",
  "sentry-types",
  "serde",
  "serde_json",
@@ -4669,7 +4729,7 @@ checksum = "0e663b3eb62ddfc023c9cf5432daf5f1a4f6acb1df4d78dd80b740b32dd1a740"
 dependencies = [
  "debugid",
  "hex",
- "rand",
+ "rand 0.8.5",
  "serde",
  "serde_json",
  "thiserror",
@@ -4872,7 +4932,7 @@ source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8fe458c98333f9c8152221191a77e2a44e8325d0193484af2e9421a53019e57d"
 dependencies = [
  "digest",
- "rand_core",
+ "rand_core 0.6.4",
 ]
 
 [[package]]
@@ -5127,7 +5187,7 @@ dependencies = [
  "memchr",
  "once_cell",
  "percent-encoding",
- "rand",
+ "rand 0.8.5",
  "rsa",
  "sha1",
  "sha2",
@@ -5165,7 +5225,7 @@ dependencies = [
  "md-5",
  "memchr",
  "once_cell",
- "rand",
+ "rand 0.8.5",
  "serde",
  "serde_json",
  "sha1",
@@ -5316,15 +5376,14 @@ dependencies = [
 
 [[package]]
 name = "tempfile"
-version = "3.5.0"
+version = "3.10.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b9fbec84f381d5795b08656e4912bec604d162bff9291d6189a78f4c8ab87998"
+checksum = "a365e8cd18e44762ef95d87f284f4b5cd04107fec2ff3052bd6a3e6069669e67"
 dependencies = [
  "cfg-if",
  "fastrand",
- "redox_syscall 0.3.5",
- "rustix 0.37.25",
- "windows-sys 0.45.0",
+ "rustix",
+ "windows-sys 0.52.0",
 ]
 
 [[package]]
@@ -5342,7 +5401,7 @@ version = "0.3.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "21bebf2b7c9e0a515f6e0f8c51dc0f8e4696391e6f1ff30379559f8365fb0df7"
 dependencies = [
- "rustix 0.38.20",
+ "rustix",
  "windows-sys 0.48.0",
 ]
 
@@ -5459,6 +5518,7 @@ dependencies = [
  "libc",
  "mio",
  "num_cpus",
+ "parking_lot",
  "pin-project-lite",
  "signal-hook-registry",
  "socket2 0.5.3",
@@ -5591,7 +5651,7 @@ dependencies = [
  "indexmap 1.9.2",
  "pin-project",
  "pin-project-lite",
- "rand",
+ "rand 0.8.5",
  "slab",
  "tokio",
  "tokio-util",
@@ -5727,7 +5787,7 @@ dependencies = [
  "idna 0.2.3",
  "ipnet",
  "lazy_static",
- "rand",
+ "rand 0.8.5",
  "smallvec",
  "thiserror",
  "tinyvec",
@@ -5774,7 +5834,7 @@ dependencies = [
  "http",
  "httparse",
  "log",
- "rand",
+ "rand 0.8.5",
  "sha1",
  "thiserror",
  "url",
@@ -5934,7 +5994,7 @@ version = "1.3.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "1674845326ee10d37ca60470760d4288a6f80f304007d92e5c53bab78c9cfd79"
 dependencies = [
- "getrandom",
+ "getrandom 0.2.8",
  "serde",
  "sha1_smol",
 ]
@@ -5951,6 +6011,16 @@ version = "0.2.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "accd4ea62f7bb7a82fe23066fb0957d48ef677f6eeb8215f372f52e48bb32426"
 
+[[package]]
+name = "vector-map"
+version = "1.0.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "550f72ae94a45c0e2139188709e6c4179f0b5ff9bdaa435239ad19048b0cd68c"
+dependencies = [
+ "contracts",
+ "rand 0.7.3",
+]
+
 [[package]]
 name = "version_check"
 version = "0.9.4"
@@ -5978,6 +6048,12 @@ dependencies = [
  "try-lock",
 ]
 
+[[package]]
+name = "wasi"
+version = "0.9.0+wasi-snapshot-preview1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "cccddf32554fecc6acb585f82a32a72e28b48f8c4c1883ddfeeeaa96f7d8e519"
+
 [[package]]
 name = "wasi"
 version = "0.11.0+wasi-snapshot-preview1"
@@ -6162,6 +6238,15 @@ dependencies = [
  "windows-targets 0.48.5",
 ]
 
+[[package]]
+name = "windows-sys"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "282be5f36a8ce781fad8c8ae18fa3f9beff57ec1b52cb3de0789201425d9a33d"
+dependencies = [
+ "windows-targets 0.52.0",
+]
+
 [[package]]
 name = "windows-targets"
 version = "0.42.1"
@@ -6192,6 +6277,21 @@ dependencies = [
  "windows_x86_64_msvc 0.48.5",
 ]
 
+[[package]]
+name = "windows-targets"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8a18201040b24831fbb9e4eb208f8892e1f50a37feb53cc7ff887feb8f50e7cd"
+dependencies = [
+ "windows_aarch64_gnullvm 0.52.0",
+ "windows_aarch64_msvc 0.52.0",
+ "windows_i686_gnu 0.52.0",
+ "windows_i686_msvc 0.52.0",
+ "windows_x86_64_gnu 0.52.0",
+ "windows_x86_64_gnullvm 0.52.0",
+ "windows_x86_64_msvc 0.52.0",
+]
+
 [[package]]
 name = "windows_aarch64_gnullvm"
 version = "0.42.1"
@@ -6204,6 +6304,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "2b38e32f0abccf9987a4e3079dfb67dcd799fb61361e53e2882c3cbaf0d905d8"
 
+[[package]]
+name = "windows_aarch64_gnullvm"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "cb7764e35d4db8a7921e09562a0304bf2f93e0a51bfccee0bd0bb0b666b015ea"
+
 [[package]]
 name = "windows_aarch64_msvc"
 version = "0.42.1"
@@ -6216,6 +6322,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "dc35310971f3b2dbbf3f0690a219f40e2d9afcf64f9ab7cc1be722937c26b4bc"
 
+[[package]]
+name = "windows_aarch64_msvc"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "bbaa0368d4f1d2aaefc55b6fcfee13f41544ddf36801e793edbbfd7d7df075ef"
+
 [[package]]
 name = "windows_i686_gnu"
 version = "0.42.1"
@@ -6228,6 +6340,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "a75915e7def60c94dcef72200b9a8e58e5091744960da64ec734a6c6e9b3743e"
 
+[[package]]
+name = "windows_i686_gnu"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "a28637cb1fa3560a16915793afb20081aba2c92ee8af57b4d5f28e4b3e7df313"
+
 [[package]]
 name = "windows_i686_msvc"
 version = "0.42.1"
@@ -6240,6 +6358,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8f55c233f70c4b27f66c523580f78f1004e8b5a8b659e05a4eb49d4166cca406"
 
+[[package]]
+name = "windows_i686_msvc"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "ffe5e8e31046ce6230cc7215707b816e339ff4d4d67c65dffa206fd0f7aa7b9a"
+
 [[package]]
 name = "windows_x86_64_gnu"
 version = "0.42.1"
@@ -6252,6 +6376,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "53d40abd2583d23e4718fddf1ebec84dbff8381c07cae67ff7768bbf19c6718e"
 
+[[package]]
+name = "windows_x86_64_gnu"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "3d6fa32db2bc4a2f5abeacf2b69f7992cd09dca97498da74a151a3132c26befd"
+
 [[package]]
 name = "windows_x86_64_gnullvm"
 version = "0.42.1"
@@ -6264,6 +6394,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "0b7b52767868a23d5bab768e390dc5f5c55825b6d30b86c844ff2dc7414044cc"
 
+[[package]]
+name = "windows_x86_64_gnullvm"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "1a657e1e9d3f514745a572a6846d3c7aa7dbe1658c056ed9c3344c4109a6949e"
+
 [[package]]
 name = "windows_x86_64_msvc"
 version = "0.42.1"
@@ -6276,6 +6412,12 @@ version = "0.48.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "ed94fce61571a4006852b7389a063ab983c02eb1bb37b47f8272ce92d06d9538"
 
+[[package]]
+name = "windows_x86_64_msvc"
+version = "0.52.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "dff9641d1cd4be8d1a070daf9e3773c5f67e78b4d9d42263020c057706765c04"
+
 [[package]]
 name = "winreg"
 version = "0.10.1"
diff --git a/relay-auth/src/lib.rs b/relay-auth/src/lib.rs
index 6b8afa366..24a54bfba 100644
--- a/relay-auth/src/lib.rs
+++ b/relay-auth/src/lib.rs
@@ -434,7 +434,7 @@ pub fn generate_key_pair() -> (SecretKey, PublicKey) {
 /// the state, use `SignedRegisterChallenge::unpack`. In both cases, a secret for signing has to be
 /// supplied.
 #[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct SignedRegisterState(String);
+pub struct SignedRegisterState(pub String);
 
 impl SignedRegisterState {
     /// Creates an Hmac instance for signing the `RegisterState`.
diff --git a/relay-crash/sentry-native b/relay-crash/sentry-native
--- a/relay-crash/sentry-native
+++ b/relay-crash/sentry-native
@@ -1 +1 @@
-Subproject commit d380374c32d58f75b16758217338ec9cc9aa5b9e
+Subproject commit d380374c32d58f75b16758217338ec9cc9aa5b9e-dirty
diff --git a/relay-dynamic-config/src/global.rs b/relay-dynamic-config/src/global.rs
index ee77bdea9..c1d3a240c 100644
--- a/relay-dynamic-config/src/global.rs
+++ b/relay-dynamic-config/src/global.rs
@@ -104,7 +104,7 @@ pub struct Options {
 
     /// All other unknown options.
     #[serde(flatten)]
-    other: HashMap<String, Value>,
+    pub other: HashMap<String, Value>,
 }
 
 /// Kill switch for controlling the cardinality limiter.
diff --git a/relay-server/src/lib.rs b/relay-server/src/lib.rs
index 965e662ea..3063a74cf 100644
--- a/relay-server/src/lib.rs
+++ b/relay-server/src/lib.rs
@@ -255,13 +255,13 @@
 
 mod constants;
 mod endpoints;
-mod envelope;
-mod extractors;
+pub mod envelope;
+pub mod extractors;
 mod http;
 mod metrics_extraction;
 mod middlewares;
 mod service;
-mod services;
+pub mod services;
 mod statsd;
 mod utils;
 
diff --git a/relay-server/src/services/outcome.rs b/relay-server/src/services/outcome.rs
index ab63931da..117b71b76 100644
--- a/relay-server/src/services/outcome.rs
+++ b/relay-server/src/services/outcome.rs
@@ -76,7 +76,7 @@ pub struct OutcomeId(u8);
 impl OutcomeId {
     // This is not an enum because we still want to forward unknown outcome IDs transparently
     const ACCEPTED: OutcomeId = OutcomeId(0);
-    const FILTERED: OutcomeId = OutcomeId(1);
+    pub const FILTERED: OutcomeId = OutcomeId(1);
     const RATE_LIMITED: OutcomeId = OutcomeId(2);
     const INVALID: OutcomeId = OutcomeId(3);
     const ABUSE: OutcomeId = OutcomeId(4);
@@ -432,29 +432,29 @@ impl fmt::Display for DiscardReason {
 #[derive(Debug, Serialize, Deserialize, Clone)]
 pub struct TrackRawOutcome {
     /// The timespan of the event outcome.
-    timestamp: String,
+    pub timestamp: String,
     /// Organization id.
     #[serde(default, skip_serializing_if = "Option::is_none")]
-    org_id: Option<u64>,
+    pub org_id: Option<u64>,
     /// Project id.
-    project_id: ProjectId,
+    pub project_id: ProjectId,
     /// The DSN project key id.
     #[serde(default, skip_serializing_if = "Option::is_none")]
-    key_id: Option<u64>,
+    pub key_id: Option<u64>,
     /// The outcome.
-    outcome: OutcomeId,
+    pub outcome: OutcomeId,
     /// Reason for the outcome.
     #[serde(default, skip_serializing_if = "Option::is_none")]
-    reason: Option<String>,
+    pub reason: Option<String>,
     /// The event id.
     #[serde(default, skip_serializing_if = "Option::is_none")]
-    event_id: Option<EventId>,
+    pub event_id: Option<EventId>,
     /// The client ip address.
     #[serde(default, skip_serializing_if = "Option::is_none")]
-    remote_addr: Option<String>,
+    pub remote_addr: Option<String>,
     /// The source of the outcome (which Relay sent it)
     #[serde(default, skip_serializing_if = "Option::is_none")]
-    source: Option<String>,
+    pub source: Option<String>,
     /// The event's data category.
     #[serde(default, skip_serializing_if = "Option::is_none")]
     pub category: Option<u8>,
diff --git a/relay-system/Cargo.toml b/relay-system/Cargo.toml
index e1b3609fb..fa4fa73cc 100644
--- a/relay-system/Cargo.toml
+++ b/relay-system/Cargo.toml
@@ -18,4 +18,4 @@ tokio = { workspace = true, features = ["rt", "signal"] }
 
 [dev-dependencies]
 relay-statsd = { path = "../relay-statsd", features = ["test"] }
-tokio = { workspace = true, features = ["test-util"] }
+tokio = { workspace = true, features = ["test-util"]  }
diff --git a/relay-test/Cargo.toml b/relay-test/Cargo.toml
index adb3174ea..a3dbe445d 100644
--- a/relay-test/Cargo.toml
+++ b/relay-test/Cargo.toml
@@ -12,4 +12,36 @@ publish = false
 [dependencies]
 relay-log = { path = "../relay-log", features = ["test"] }
 relay-system = { path = "../relay-system" }
-tokio = { workspace = true }
+tokio = { workspace = true, features = ["full"]}
+serde = { workspace = true }
+serde_json = { workspace = true }
+relay-server = { path = "../relay-server" }
+relay-base-schema = { path = "../relay-base-schema" }
+uuid = { workspace = true }
+reqwest = { version = "0.11", features = ["blocking"] }
+tempfile = "3.8.0"
+serde_yaml = { workspace = true }
+relay-event-schema = { path = "../relay-event-schema" }
+relay-sampling = { path = "../relay-sampling" }
+relay-protocol = { path = "../relay-protocol" }
+relay-common = { path = "../relay-common" }
+relay-quotas = { path = "../relay-quotas" }
+chrono = "0.4"
+hyper = "0.14"
+lazy_static = "1.4"
+relay-dynamic-config = { path = "../relay-dynamic-config" }
+relay-config = { path = "../relay-config" }
+relay-auth = { path = "../relay-auth" }
+no_deadlocks = "1.3.2"
+flate2 = "1.0.19"
+axum = { version = "0.6.20", features = [
+    "headers",
+    "macros",
+    "matched-path",
+    "multipart",
+    "tracing",
+] }
+axum-server = "0.4.7"
+
+
+
diff --git a/relay-test/src/lib.rs b/relay-test/src/lib.rs
index 138c76724..7193fb6a2 100644
--- a/relay-test/src/lib.rs
+++ b/relay-test/src/lib.rs
@@ -8,9 +8,9 @@
 //!
 //! # Example
 //!
-//! ```no_run
+//! ```
 //! #[test]
-//! fn my_test() {
+//! pub fn my_test() {
 //!     relay_test::setup();
 //!
 //!     relay_log::debug!("hello, world!");
@@ -23,8 +23,441 @@
 )]
 #![allow(clippy::derive_partial_eq_without_eq)]
 
+use std::collections::HashMap;
+use std::net::{Ipv4Addr, SocketAddrV4, TcpListener};
+use std::path::PathBuf;
+use std::process::Child;
+
+use chrono::Utc;
+use relay_auth::PublicKey;
+use relay_base_schema::project::{ProjectId, ProjectKey};
+use relay_dynamic_config::{ErrorBoundary, GlobalConfig, TransactionMetricsConfig};
+use relay_event_schema::protocol::EventId;
+use relay_sampling::config::{RuleType, SamplingRule};
+use relay_sampling::SamplingConfig;
+use relay_server::envelope::AttachmentType;
+use relay_server::envelope::Envelope;
+use relay_server::envelope::ItemType;
+use relay_server::services::project::ProjectState;
+use relay_server::services::project::PublicKeyConfig;
 use relay_system::{channel, Addr, Interface};
+use serde::{Deserialize, Serialize};
+use serde_json::{json, Map, Value};
+use std::str::FromStr;
 use tokio::task::JoinHandle;
+use uuid::Uuid;
+
+pub mod mini_sentry;
+pub mod relay;
+
+#[derive(Debug, Clone)]
+pub struct RawEnvelope {
+    pub http_headers: HashMap<String, String>,
+    pub project_id: ProjectId,
+    pub headers: HashMap<String, Value>,
+    pub items: Vec<RawItem>,
+}
+
+impl Default for RawEnvelope {
+    fn default() -> Self {
+        Self {
+            project_id: ProjectId::new(42),
+            http_headers: Default::default(),
+            headers: Default::default(),
+            items: Default::default(),
+        }
+    }
+}
+
+impl RawEnvelope {
+    pub fn new() -> Self {
+        Self::default()
+    }
+
+    pub fn is_sampled(&self) -> Option<bool> {
+        dbg!(self);
+        todo!()
+    }
+
+    pub fn parse_dsn(dsn: &str) -> (ProjectKey, ProjectId) {
+        let trimmed_dsn = dsn.trim_matches('"');
+        let trimmed_dsn = trimmed_dsn.trim_start_matches("http://");
+
+        let parts: Vec<&str> = trimmed_dsn.split([':', '@', '/']).collect();
+        let public_key = parts[0].to_string();
+        let _host = parts[2];
+        let _port = parts[3];
+        let project_id_str = parts[4];
+
+        let project_id = project_id_str.parse::<u64>().unwrap();
+
+        let public_key = ProjectKey::from_str(&public_key).unwrap();
+        let project_id = ProjectId::new(project_id);
+
+        (public_key, project_id)
+    }
+
+    pub fn from_envelope(envelope: &Envelope) -> Self {
+        let mut writer = vec![];
+        envelope.serialize(&mut writer).unwrap();
+
+        let serialized_envelope: String = String::from_utf8(writer.clone()).unwrap();
+
+        let parts: Vec<&str> = serialized_envelope.split('\n').collect();
+        let envelope_headers: Value = serde_json::from_str(parts[0]).unwrap();
+        let envelope_headers: HashMap<String, Value> = envelope_headers
+            .as_object()
+            .unwrap()
+            .clone()
+            .into_iter()
+            .collect();
+
+        let (_, project_id) = Self::parse_dsn(&envelope_headers.get("dsn").unwrap().to_string());
+
+        let item_headers: Value = serde_json::from_str(parts[1]).unwrap();
+        let item_headers: HashMap<String, Value> = item_headers
+            .as_object()
+            .unwrap()
+            .clone()
+            .into_iter()
+            .collect();
+
+        let payload: Value = serde_json::from_str(parts[2]).unwrap();
+
+        let item = RawItem::from_parts(item_headers, PayLoad::Json(payload));
+
+        Self {
+            http_headers: Default::default(),
+            project_id,
+            headers: envelope_headers,
+            items: vec![item],
+        }
+    }
+
+    pub fn add_transaction_and_trace_info(
+        self,
+        public_key: ProjectKey,
+        transaction: Option<&str>,
+    ) -> Self {
+        let (item, trace_id, _) = x_create_transaction_item(transaction);
+
+        self.add_raw_item(item)
+            .add_trace_info_simple(trace_id, public_key)
+    }
+
+    pub fn add_transaction_and_trace_info_not_simple(
+        self,
+        public_key: ProjectKey,
+        transaction: Option<&str>,
+        client_sample_rate: Option<f32>,
+    ) -> Self {
+        let (item, trace_id, _) = x_create_transaction_item(transaction);
+
+        self.add_raw_item(item).add_trace_info(
+            trace_id,
+            public_key,
+            None,
+            None,
+            client_sample_rate,
+            transaction,
+        )
+    }
+
+    pub fn add_trace_info_simple(mut self, trace_id: Uuid, public_key: ProjectKey) -> Self {
+        let trace_info = json!({
+            "trace_id": dbg!(trace_id.simple().to_string()),
+            "public_key": public_key,
+        });
+
+        self.headers.insert("trace".into(), trace_info);
+        self
+    }
+
+    pub fn add_error_event_with_trace_info(self, public_key: ProjectKey) -> Self {
+        let (item, trace_id, event_id) = create_error_item();
+
+        self.add_raw_item(item)
+            .set_event_id(event_id)
+            .add_trace_info(
+                trace_id,
+                public_key,
+                Some(1.0),
+                Some(true),
+                Some(1.0),
+                Some("/transaction"),
+            )
+    }
+
+    pub fn add_trace_info(
+        mut self,
+        trace_id: Uuid,
+        public_key: ProjectKey,
+        release: Option<f32>,
+        sampled: Option<bool>,
+        client_sample_rate: Option<f32>,
+        transaction: Option<&str>,
+    ) -> Self {
+        let mut x = json!({
+            "trace_id": dbg!(trace_id.simple().to_string()),
+            "public_key": public_key,
+        });
+
+        let trace_info = x.as_object_mut().unwrap();
+
+        if let Some(release) = release {
+            let release = format!("{:.1}", release);
+            trace_info.insert("release".to_string(), release.into());
+        }
+
+        if let Some(sample_rate) = client_sample_rate {
+            let sample_rate = format!("{:.5}", sample_rate);
+            trace_info.insert("sample_rate".to_string(), sample_rate.into());
+        }
+
+        if let Some(transaction) = transaction {
+            trace_info.insert("transaction".to_string(), transaction.into());
+        }
+
+        if let Some(sampled) = sampled {
+            trace_info.insert("sampled".to_string(), sampled.into());
+        }
+
+        dbg!(&trace_info);
+
+        self.headers.insert(
+            "trace".into(),
+            serde_json::Value::Object(trace_info.to_owned()),
+        );
+        self
+    }
+
+    pub fn set_project_id(mut self, id: ProjectId) -> Self {
+        self.project_id = id;
+        self
+    }
+
+    pub fn set_event_id(self, id: Uuid) -> Self {
+        self.add_header("event_id", &id.to_string())
+    }
+
+    pub fn add_header(mut self, key: &str, val: &str) -> Self {
+        self.headers.insert(key.into(), val.into());
+        self
+    }
+
+    pub fn add_http_header(mut self, key: &str, val: &str) -> Self {
+        self.http_headers.insert(key.into(), val.into());
+        self
+    }
+
+    pub fn add_raw_item(mut self, item: RawItem) -> Self {
+        self.items.push(item);
+        self
+    }
+
+    pub fn add_item_from_json(mut self, payload: Value, ty: ItemType) -> Self {
+        let item = RawItem::from_json(payload).set_type(ty);
+        self.items.push(item);
+        self
+    }
+
+    pub fn add_item(mut self, payload: &str, ty: ItemType) -> Self {
+        let item = RawItem::from_json(payload.into()).set_type(ty);
+        self.items.push(item);
+        self
+    }
+
+    pub fn add_attachment(mut self, payload: &str, ty: impl Into<Option<AttachmentType>>) -> Self {
+        let ty = ty.into();
+        let mut item = RawItem::from_json(payload.into()).set_type(ItemType::Attachment);
+
+        if let Some(ty) = ty {
+            item = item.add_header("attachment_type", &ty.to_string());
+        };
+
+        self.items.push(item);
+        self
+    }
+
+    pub fn add_transaction(mut self, payload: Value) -> Self {
+        let item = RawItem::from_json(payload).set_type(ItemType::Event);
+        self.items.push(item);
+        self
+    }
+
+    pub fn add_event(mut self, payload: &str) -> Self {
+        let item = RawItem::from_bytes(payload.to_string()).set_type(ItemType::Event);
+        self.items.push(item);
+        self
+    }
+
+    pub fn serialize(&self) -> String {
+        let mut serialized = String::new();
+
+        // Serialize envelope-level headers as JSON
+        let headers_json = serde_json::to_string(&self.headers).unwrap();
+        serialized.push_str(&format!("{}\n", headers_json));
+
+        // Serialize items, which are already adjusted to include JSON headers
+        for item in &self.items {
+            serialized.push_str(item.serialize().as_str());
+        }
+
+        serialized
+    }
+}
+
+#[derive(Debug, Clone)]
+pub enum PayLoad {
+    Json(Value),
+    Bytes(Vec<u8>),
+}
+
+#[derive(Debug, Clone)]
+pub struct RawItem {
+    headers: HashMap<String, Value>,
+    payload: PayLoad,
+}
+
+impl RawItem {
+    pub fn from_bytes(payload: impl Into<Vec<u8>>) -> Self {
+        let vec = payload.into();
+        let value: Value = serde_json::from_slice(vec.as_slice()).unwrap();
+
+        let mut headers = HashMap::default();
+
+        for (key, value) in value.as_object().unwrap().iter() {
+            headers.insert(key.clone(), value.clone());
+        }
+
+        Self {
+            headers,
+            payload: PayLoad::Bytes(vec),
+        }
+    }
+
+    pub fn sampled(&self) -> Option<bool> {
+        dbg!(self);
+        self.payload()
+            .as_object()?
+            .get("contexts")?
+            .as_object()?
+            .get("trace")?
+            .as_object()?
+            .get("sampled")?
+            .as_bool()
+    }
+
+    pub fn event_id(&self) -> Option<EventId> {
+        let as_str = self
+            .payload()
+            .as_object()
+            .unwrap()
+            .get("event_id")?
+            .to_string();
+        let as_str = as_str.trim_matches('\"');
+        let id = Uuid::parse_str(as_str).unwrap();
+
+        Some(EventId(id))
+    }
+
+    pub fn from_parts(headers: HashMap<String, Value>, payload: PayLoad) -> Self {
+        Self { headers, payload }
+    }
+
+    pub fn ty(&self) -> ItemType {
+        let as_str = self.headers.get("type").unwrap().to_string();
+        let as_str = as_str.trim_matches('\"');
+        ItemType::from_str(as_str).unwrap()
+    }
+
+    pub fn from_json(payload: Value) -> Self {
+        let mut headers = HashMap::default();
+
+        for (key, value) in payload.as_object().unwrap().iter() {
+            headers.insert(key.clone(), value.clone());
+        }
+
+        Self {
+            headers,
+            payload: PayLoad::Json(payload),
+        }
+    }
+
+    pub fn payload_string(&self) -> String {
+        match &self.payload {
+            PayLoad::Json(json) => json.to_string(),
+            PayLoad::Bytes(bytes) => String::from_utf8(bytes.clone()).unwrap(),
+        }
+    }
+
+    pub fn payload(&self) -> Value {
+        serde_json::from_str(&self.payload_string()).unwrap()
+    }
+
+    pub fn inferred_content_type(&self) -> &'static str {
+        match self.payload {
+            PayLoad::Json(_) => "application/json",
+            PayLoad::Bytes(_) => "application/octet-stream",
+        }
+    }
+
+    pub fn add_header_from_json(mut self, key: &str, val: Value) -> Self {
+        self.headers.insert(key.into(), val);
+        self
+    }
+
+    pub fn add_header(mut self, key: &str, val: &str) -> Self {
+        self.headers.insert(key.into(), val.into());
+        self
+    }
+
+    pub fn set_type(mut self, ty: ItemType) -> Self {
+        let ty: String = ty.to_string();
+        self.headers.insert("type".into(), ty.into());
+        self
+    }
+
+    // Serialize the RawItem for inclusion in RawEnvelope's serialization
+    pub fn serialize(&self) -> String {
+        let mut headers = self.headers.clone();
+        // Assuming payload length is desired in bytes, considering UTF-8 encoding
+        let payload = self.payload_string();
+        headers.insert(
+            "length".to_owned(),
+            serde_json::Value::Number(payload.len().into()),
+        );
+
+        headers.insert(
+            "content_type".to_owned(),
+            self.inferred_content_type().into(),
+        );
+
+        // Serialize headers to JSON string
+        dbg!(&headers);
+        let headers_json = serde_json::to_string(&headers).unwrap();
+        dbg!(&headers_json);
+        let serialized = format!("{}\n{}\n", headers_json, payload);
+
+        dbg!(serialized)
+    }
+}
+
+pub fn create_error_item() -> (RawItem, Uuid, Uuid) {
+    let trace_id = Uuid::new_v4();
+    let event_id = Uuid::new_v4();
+    let error_event = json!({
+        "event_id": event_id.simple(),
+        "message": "This is an error.",
+        "extra": {"msg_text": "This is an error", "id": event_id.simple()},
+        "type": "error",
+        "environment": "production",
+        "release": "foo@1.2.3",
+    });
+
+    let item = RawItem::from_json(error_event).set_type(ItemType::Event);
+    (item, trace_id, event_id)
+}
 
 /// Setup the test environment.
 ///
@@ -34,8 +467,6 @@ pub fn setup() {
 }
 
 /// Spawns a mock service that handles messages through a closure.
-///
-/// Note: Addr must be dropped before handle can be awaited.
 pub fn mock_service<S, I, F>(name: &'static str, mut state: S, mut f: F) -> (Addr<I>, JoinHandle<S>)
 where
     S: Send + 'static,
@@ -54,3 +485,406 @@ where
 
     (addr, handle)
 }
+
+pub fn random_port() -> u16 {
+    let loopback = Ipv4Addr::new(127, 0, 0, 1);
+    let socket = SocketAddrV4::new(loopback, 0);
+    let listener = TcpListener::bind(socket).expect("Failed to bind to address");
+    listener
+        .local_addr()
+        .expect("Failed to get local address")
+        .port()
+}
+
+pub const DEFAULT_DSN_PUBLIC_KEY: &str = "31a5a894b4524f74a9a8d0e27e21ba91";
+
+#[derive(Debug, Deserialize, Serialize)]
+pub struct ProjectResponse {
+    configs: HashMap<ProjectKey, ErrorBoundary<Option<ProjectState>>>,
+    pending: Vec<ProjectKey>,
+    global: Option<GlobalConfig>,
+}
+
+pub struct BackgroundProcess {
+    pub child: Option<Child>,
+}
+
+impl BackgroundProcess {
+    pub fn new(command: &str, args: &[&str]) -> Self {
+        let child = std::process::Command::new(command)
+            .args(args)
+            .spawn()
+            .expect("Failed to start process");
+
+        BackgroundProcess { child: Some(child) }
+    }
+}
+
+impl Drop for BackgroundProcess {
+    fn drop(&mut self) {
+        if let Some(mut child) = self.child.take() {
+            let _ = child.kill();
+            let _ = child.wait();
+        }
+    }
+}
+
+pub struct TempDir {
+    base_dir: PathBuf,
+}
+
+impl Default for TempDir {
+    fn default() -> Self {
+        TempDir {
+            base_dir: tempfile::tempdir()
+                .expect("Failed to create temp dir")
+                .into_path(),
+        }
+    }
+}
+
+impl TempDir {
+    pub fn create(&mut self, name: &str) -> PathBuf {
+        let dir_path = self.base_dir.join(name);
+        if dir_path.exists() {
+            panic!("IT ALREADY EXISTS!!");
+        }
+        std::fs::create_dir(&dir_path).expect("Failed to create config dir");
+
+        dir_path
+    }
+}
+
+#[derive(Clone)]
+pub struct StateBuilder {
+    project_id: ProjectId,
+    trusted_relays: Vec<PublicKey>,
+    dsn_public_key_config: PublicKeyConfig,
+    sampling_rules: Vec<SamplingRule>,
+    transaction_metrics_version: Option<u32>,
+    outcomes: Option<Value>,
+}
+
+impl From<StateBuilder> for ProjectState {
+    fn from(value: StateBuilder) -> Self {
+        value.build()
+    }
+}
+
+impl StateBuilder {
+    pub fn new() -> Self {
+        Self {
+            project_id: ProjectId::new(42),
+            trusted_relays: vec![],
+            dsn_public_key_config: {
+                let public_key: ProjectKey = Uuid::new_v4().simple().to_string().parse().unwrap();
+                let numeric_id = Some(123);
+
+                PublicKeyConfig {
+                    public_key,
+                    numeric_id,
+                }
+            },
+            sampling_rules: vec![],
+            transaction_metrics_version: None,
+            outcomes: None,
+        }
+    }
+
+    pub fn public_key(&self) -> ProjectKey {
+        self.dsn_public_key_config.public_key
+    }
+
+    pub fn enable_outcomes(mut self) -> Self {
+        self.outcomes = Some(json!({
+            "outcomes": {
+            "emit_outcomes": true,
+            "batch_size": 1,
+            "batch_interval": 1,
+            "source": "relay"
+        }}));
+        self
+    }
+
+    pub fn set_sampling_rule(self, sample_rate: f32, rule_type: RuleType) -> Self {
+        let rule = new_sampling_rule(sample_rate, rule_type.into(), vec![], None, None);
+        self.add_sampling_rule(rule)
+    }
+
+    pub fn set_transaction_metrics_version(mut self, version: u32) -> Self {
+        self.transaction_metrics_version = Some(version);
+        self
+    }
+
+    pub fn set_project_id(mut self, id: ProjectId) -> Self {
+        self.project_id = id;
+        self
+    }
+
+    pub fn add_trusted_relays(mut self, relays: Vec<PublicKey>) -> Self {
+        self.trusted_relays.extend(relays);
+        self
+    }
+
+    pub fn add_sampling_rules(mut self, rules: Vec<SamplingRule>) -> Self {
+        self.sampling_rules.extend(rules);
+        self
+    }
+
+    pub fn add_sampling_rule(mut self, rule: SamplingRule) -> Self {
+        self.sampling_rules.push(rule);
+        self
+    }
+
+    pub fn add_basic_sampling_rule(mut self, rule_type: RuleType, sample_rate: f32) -> Self {
+        let rule = new_sampling_rule(sample_rate, Some(rule_type), vec![], None, None);
+        self.sampling_rules.push(rule);
+        self
+    }
+
+    pub fn build(self) -> ProjectState {
+        let last_fetch = Utc::now().to_rfc3339_opts(chrono::SecondsFormat::Secs, true);
+        let last_change = Utc::now().to_rfc3339_opts(chrono::SecondsFormat::Secs, true);
+
+        let json = json!({
+        "projectId": self.project_id,
+        "slug": "python",
+        "publicKeys": [self.dsn_public_key_config],
+        "rev": "5ceaea8c919811e8ae7daae9fe877901",
+        "disabled": false,
+        "lastFetch": last_fetch,
+        "lastChange": last_change,
+        "config": {
+            "allowedDomains": ["*"],
+            "trustedRelays": self.trusted_relays,
+            "transaction_metrics": {
+                "version": self.transaction_metrics_version,
+            },
+            "piiConfig": {
+                "rules": {},
+                "applications": {
+                    "$string": ["@email", "@mac", "@creditcard", "@userpath"],
+                    "$object": ["@password"],
+                    },
+                },
+            }
+        });
+
+        let mut project_state: ProjectState = serde_json::from_value(json).unwrap();
+
+        let mut sampling_config = SamplingConfig::new();
+        sampling_config.rules = self.sampling_rules.clone();
+        project_state.config.sampling = Some(ErrorBoundary::Ok(sampling_config));
+
+        if let Some(tv) = self.transaction_metrics_version {
+            let mut x = TransactionMetricsConfig::new();
+            x.version = tv as u16;
+            project_state.config.transaction_metrics = Some(ErrorBoundary::Ok(x));
+        }
+
+        project_state
+    }
+}
+
+impl Default for StateBuilder {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+pub fn new_sampling_rule(
+    sample_rate: f32,
+    rule_type: Option<RuleType>,
+    releases: Vec<f32>,
+    user_segments: Option<()>,
+    environments: Option<()>,
+) -> SamplingRule {
+    let releases: Vec<String> = releases.iter().map(|x| format!("{:.1}", x)).collect();
+
+    let rule_type = rule_type.unwrap_or(RuleType::Trace);
+
+    let mut conditions: Vec<Value> = vec![];
+
+    let field_prefix = match rule_type {
+        RuleType::Trace => "trace.",
+        RuleType::Transaction => "event.",
+        RuleType::Unsupported => panic!(),
+    };
+
+    if !releases.is_empty() {
+        conditions.push(json!({
+            "op": "glob",
+            "name": format!("{}{}", field_prefix, "release",),
+            "value": releases,
+        }));
+    }
+
+    if user_segments.is_some() {
+        conditions.push(json!(
+        {
+            "op": "eq",
+            "name": format!("{}{}", field_prefix, "user"),
+            "value": user_segments,
+            "options": {
+                "ignoreCase": true,
+            },
+        }));
+    }
+
+    if environments.is_some() {
+        conditions.push(json!(
+            {
+                "op": "eq",
+                "name": format!("{}{}", field_prefix , "environment"),
+                "value": environments,
+                "options": {
+                    "ignoreCase": true,
+                },
+            }
+        ))
+    }
+
+    serde_json::from_value(json! ({
+        "samplingValue": {"type": "sampleRate", "value": sample_rate},
+        "type": rule_type,
+        "condition": {"op": "and", "inner": conditions},
+        "id": 1,
+    }))
+    .unwrap()
+}
+
+pub fn merge(mut base: Value, merge_value: Value, keys: Vec<&str>) -> Value {
+    dbg!(&base, &merge_value, &keys);
+    let mut base_map = base.as_object_mut().expect("base should be an object");
+
+    // Navigate down the nested structure to the final map where the merge should occur
+    for key in keys {
+        if !base_map.contains_key(key) {
+            // If the key doesn't exist at this level, create a new object for it
+            base_map.insert(key.to_string(), Value::Object(Map::new()));
+        }
+        // Now we're sure the key exists, navigate into it
+        base_map = base_map.get_mut(key).unwrap().as_object_mut().unwrap();
+    }
+
+    let merge_map = merge_value
+        .as_object()
+        .expect("merge_value should be an object");
+
+    for (key, merge_val) in merge_map {
+        if let Some(existing_val) = base_map.get_mut(key) {
+            // If the key exists, and both existing and merging values are objects, merge recursively
+            if let (Some(existing_obj), Some(merge_obj)) =
+                (existing_val.as_object_mut(), merge_val.as_object())
+            {
+                for (merge_key, val) in merge_obj {
+                    existing_obj.insert(merge_key.clone(), val.clone());
+                }
+                continue;
+            }
+        }
+        // If the key doesn't exist, or the existing value is not an object, insert/replace directly
+        base_map.insert(key.clone(), merge_val.clone());
+    }
+
+    base
+}
+
+pub fn outcomes_enabled_config() -> Value {
+    json!({
+        "outcomes": {
+            "emit_outcomes": true,
+            "batch_size": 1,
+            "batch_interval": 1,
+            "source": "relay"
+    }})
+}
+
+pub fn opt_create_transaction_item(
+    transaction: Option<&str>,
+    trace_id: Option<Uuid>,
+    event_id: Option<Uuid>,
+) -> (RawItem, Uuid, Uuid) {
+    let trace_id = trace_id.unwrap_or_else(Uuid::new_v4);
+    let event_id = event_id.unwrap_or_else(Uuid::new_v4);
+
+    let item = json!({
+        "event_id": event_id,
+        "transaction": transaction.unwrap_or( "tr1"),
+        "start_timestamp": 1597976392.6542819,
+        "timestamp": 1597976400.6189718,
+        "contexts": {
+            "trace": {
+                "trace_id": trace_id.simple(),
+                "span_id": "FA90FDEAD5F74052",
+                "type": "trace",
+            }
+        },
+        "spans": [],
+        "extra": {"id": event_id},
+    });
+
+    let item = RawItem::from_json(item).set_type(ItemType::Transaction);
+    (item, trace_id, event_id)
+}
+
+pub fn x_create_transaction_item(transaction: Option<&str>) -> (RawItem, Uuid, Uuid) {
+    let trace_id = Uuid::new_v4();
+    let event_id = Uuid::new_v4();
+
+    let item = json!({
+        "event_id": event_id,
+        "transaction": transaction.unwrap_or( "tr1"),
+        "start_timestamp": 1597976392.6542819,
+        "timestamp": 1597976400.6189718,
+        "contexts": {
+            "trace": {
+                "trace_id": trace_id.simple(),
+                "span_id": "FA90FDEAD5F74052",
+                "type": "trace",
+            }
+        },
+        "spans": [],
+        "extra": {"id": event_id},
+    });
+
+    let item = RawItem::from_json(item).set_type(ItemType::Transaction);
+    (item, trace_id, event_id)
+}
+
+pub fn get_topic_name(topic: &str) -> String {
+    let random = Uuid::new_v4().simple().to_string();
+    format!("relay-test-{}-{}", topic, random)
+}
+
+pub fn processing_config() -> Value {
+    let bootstrap_servers =
+        std::env::var("KAFKA_BOOTSTRAP_SERVER").unwrap_or_else(|_| "127.0.0.1:49092".to_string());
+
+    json!({
+        "processing": {
+            "enabled": true,
+            "kafka_config": [
+                {
+                    "name": "bootstrap.servers",
+                    "value": bootstrap_servers
+                }
+            ],
+            "topics": {
+                "events": get_topic_name("events"),
+                "attachments": get_topic_name("attachments"),
+                "transactions": get_topic_name("transactions"),
+                "outcomes": get_topic_name("outcomes"),
+                "sessions": get_topic_name("sessions"),
+                "metrics": get_topic_name("metrics"),
+                "metrics_generic": get_topic_name("metrics"),
+                "replay_events": get_topic_name("replay_events"),
+                "replay_recordings": get_topic_name("replay_recordings"),
+                "monitors": get_topic_name("monitors"),
+                "spans": get_topic_name("spans")
+            },
+            "redis": "redis://127.0.0.1",
+            "projectconfig_cache_prefix": format!("relay-test-relayconfig-{}", uuid::Uuid::new_v4())
+        }
+    })
+}
diff --git a/relay-test/src/mini_sentry.rs b/relay-test/src/mini_sentry.rs
new file mode 100644
index 000000000..fa1420f14
--- /dev/null
+++ b/relay-test/src/mini_sentry.rs
@@ -0,0 +1,628 @@
+use no_deadlocks::Mutex;
+use relay_event_schema::protocol::EventId;
+use std::collections::HashMap;
+use std::io::Read;
+use std::net::SocketAddr;
+use std::pin::Pin;
+use std::sync::Arc;
+use std::time::Duration;
+
+use crate::{
+    random_port, ProjectResponse, RawEnvelope, RawItem, StateBuilder, DEFAULT_DSN_PUBLIC_KEY,
+};
+use axum::body::Bytes;
+use axum::response::Json;
+use axum::routing::{get, post};
+use axum::Router;
+use flate2::read::GzDecoder;
+use relay_auth::{PublicKey, RelayId, RelayVersion, SignedRegisterState};
+use relay_base_schema::project::{ProjectId, ProjectKey};
+use relay_config::RelayInfo;
+use relay_dynamic_config::{ErrorBoundary, GlobalConfig, Options};
+use relay_sampling::config::SamplingRule;
+use relay_sampling::SamplingConfig;
+use relay_server::envelope::Envelope as RelayEnvelope;
+use relay_server::envelope::ItemType;
+use relay_server::services::outcome::OutcomeId;
+use relay_server::services::outcome::TrackRawOutcome;
+use relay_server::services::project::ProjectState;
+use relay_server::services::project::PublicKeyConfig;
+use serde_json::{json, Value};
+use std::future::Future;
+use tokio::runtime::Runtime;
+use uuid::Uuid;
+
+#[derive(Default, Clone)]
+pub struct CapturedOutcomes {
+    inner: Arc<Mutex<Vec<TrackRawOutcome>>>,
+}
+
+impl CapturedOutcomes {
+    pub fn is_empty(&self) -> bool {
+        self.inner.lock().unwrap().is_empty()
+    }
+
+    pub fn clear(&self) -> &Self {
+        self.inner.lock().unwrap().clear();
+        self
+    }
+
+    pub fn pop(&self) -> Option<TrackRawOutcome> {
+        self.inner.lock().unwrap().pop()
+    }
+
+    pub fn extend(&self, outcomes: Vec<TrackRawOutcome>) {
+        self.inner.lock().unwrap().extend(outcomes);
+    }
+
+    pub fn push(&self, outcome: TrackRawOutcome) {
+        self.inner.lock().unwrap().push(outcome);
+    }
+
+    pub fn take_index(&self, idx: usize) -> TrackRawOutcome {
+        self.inner.lock().unwrap().remove(idx)
+    }
+
+    pub fn assert_outcome_qty(&self, qty: usize) -> &Self {
+        assert_eq!(self.inner.lock().unwrap().len(), qty);
+        self
+    }
+
+    pub fn assert_all_outcome_reasons(&self, reason: &str) -> &Self {
+        let guard = self.inner.lock().unwrap();
+
+        for outcome in guard.iter() {
+            assert_eq!(outcome.reason.clone().unwrap().as_str(), reason);
+        }
+        self
+    }
+
+    pub fn assert_all_outcome_id(&self, ty: OutcomeId) -> &Self {
+        let guard = self.inner.lock().unwrap();
+
+        for outcome in guard.iter() {
+            assert_eq!(outcome.outcome, ty);
+        }
+        self
+    }
+
+    pub fn wait_for_outcome(&self, timeout: u64) -> &Self {
+        for _ in 0..timeout {
+            if !self.is_empty() {
+                return self;
+            }
+            std::thread::sleep(Duration::from_secs(1));
+        }
+
+        panic!("timed out while waiting for outcome");
+    }
+
+    pub fn wait(&self, secs: u64) -> &Self {
+        std::thread::sleep(Duration::from_secs(secs));
+        self
+    }
+
+    pub fn assert_empty(&self) -> &Self {
+        self.assert_outcome_qty(0);
+        self
+    }
+
+    pub fn assert_not_empty(&self) -> &Self {
+        assert!(!self.inner.lock().unwrap().is_empty());
+        self
+    }
+}
+
+#[derive(Default, Clone)]
+pub struct CapturedEnvelopes {
+    inner: Arc<Mutex<Vec<RawEnvelope>>>,
+}
+
+impl CapturedEnvelopes {
+    pub fn is_empty(&self) -> bool {
+        self.inner.lock().unwrap().is_empty()
+    }
+
+    pub fn clear(&self) -> &Self {
+        self.inner.lock().unwrap().clear();
+        self
+    }
+
+    pub fn pop(&self) -> Option<RawEnvelope> {
+        self.inner.lock().unwrap().pop()
+    }
+
+    pub fn push(&self, envelope: RawEnvelope) {
+        self.inner.lock().unwrap().push(envelope);
+    }
+
+    pub fn get_index(&self, idx: usize) -> RawEnvelope {
+        self.inner.lock().unwrap().remove(idx)
+    }
+
+    pub fn assert_all_sampled_status(&self, sampled_status: bool) -> &Self {
+        for item in self.get_items() {
+            assert_eq!(item.sampled().unwrap(), sampled_status);
+        }
+
+        self
+    }
+
+    pub fn assert_envelope_qty(&self, qty: usize) -> &Self {
+        assert_eq!(self.inner.lock().unwrap().len(), qty);
+        self
+    }
+
+    pub fn assert_item_qty(&self, qty: usize) -> &Self {
+        assert_eq!(self.get_items().len(), qty);
+        self
+    }
+
+    /// Fails if any itemtype is different than the given item type.
+    pub fn assert_all_item_types(&self, ty: ItemType) -> &Self {
+        for item in self.get_items() {
+            assert_eq!(item.ty(), ty);
+        }
+
+        self
+    }
+
+    pub fn get_envelopes(&self) -> Vec<RawEnvelope> {
+        let guard = self.inner.lock().unwrap();
+
+        let mut events = vec![];
+        for envelope in guard.iter() {
+            events.push(envelope.clone());
+        }
+        events
+    }
+
+    pub fn wait_for_n_envelope(&self, n: usize, timeout: u64) -> &Self {
+        for _ in 0..timeout {
+            if self.inner.lock().unwrap().len() >= n {
+                return self;
+            }
+            std::thread::sleep(Duration::from_secs(1));
+        }
+
+        panic!("timed out while waiting for envelope");
+    }
+
+    fn get_items(&self) -> Vec<RawItem> {
+        let mut items = vec![];
+
+        for envelope in self.get_envelopes() {
+            for item in envelope.items {
+                items.push(item);
+            }
+        }
+
+        items
+    }
+
+    pub fn assert_n_item_types(&self, ty: ItemType, n: usize) -> &Self {
+        let mut matches = 0;
+
+        for item in self.get_items() {
+            if item.ty() == ty {
+                matches += 1;
+            }
+        }
+
+        assert_eq!(matches, n);
+        self
+    }
+
+    pub fn wait_for_envelope(&self, timeout: u64) -> &Self {
+        self.wait_for_n_envelope(1, timeout)
+    }
+
+    pub fn debug(&self) -> &Self {
+        dbg!(self.get_envelopes());
+        self
+    }
+
+    pub fn wait(&self, secs: u64) -> &Self {
+        std::thread::sleep(Duration::from_secs(secs));
+        self
+    }
+
+    pub fn assert_empty(&self) -> &Self {
+        self.assert_envelope_qty(0)
+    }
+
+    /// Checks if any item corresponds to the given event id.
+    pub fn assert_contains_event_id(&self, event_id: EventId) -> &Self {
+        for item in self.get_items() {
+            if let Some(id) = item.event_id() {
+                if id == event_id {
+                    return self;
+                }
+            }
+        }
+
+        panic!("No items with event id: {}", event_id);
+    }
+}
+
+pub struct MiniSentry {
+    pub inner: Arc<Mutex<MiniSentryInner>>,
+}
+
+pub struct MiniSentryInner {
+    server_address: SocketAddr,
+    captured_envelopes: CapturedEnvelopes,
+    captured_outcomes: CapturedOutcomes,
+    pub known_relays: HashMap<RelayId, RelayInfo>,
+    server_handle: Option<tokio::task::JoinHandle<()>>,
+    runtime: Runtime,
+    project_configs: HashMap<ProjectId, ProjectState>,
+    pub global_config: GlobalConfig,
+}
+
+impl MiniSentryInner {
+    pub fn internal_error_dsn(&self) -> String {
+        format!(
+            "http://{}@{}:{}/666",
+            DEFAULT_DSN_PUBLIC_KEY,
+            self.server_address.ip(),
+            self.server_address.port()
+        )
+    }
+
+    fn add_project_state(&mut self, project_state: ProjectState) {
+        let project_id = project_state.project_id.unwrap();
+        self.project_configs.insert(project_id, project_state);
+    }
+
+    pub fn url(&self) -> String {
+        format!("http://127.0.0.1:{}", self.server_address.port())
+    }
+}
+
+impl Default for MiniSentry {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+impl MiniSentry {
+    pub fn insert_known_relay(&self, relay_id: Uuid, public_key: PublicKey) {
+        self.inner.lock().unwrap().known_relays.insert(
+            relay_id,
+            RelayInfo {
+                public_key,
+                internal: true,
+            },
+        );
+    }
+
+    pub fn get_captured_envelopes(&self, timeout: u64) -> Option<CapturedEnvelopes> {
+        let mut i = 0;
+        loop {
+            let envelopes = self.inner.lock().unwrap().captured_envelopes.clone();
+            if !envelopes.is_empty() {
+                return Some(envelopes);
+            }
+            std::thread::sleep(Duration::from_secs(1));
+            i += 1;
+
+            if i == timeout {
+                return None;
+            }
+        }
+    }
+
+    pub fn set_global_options(self, options: Options) -> Self {
+        self.inner.lock().unwrap().global_config.options = options;
+        self
+    }
+
+    pub fn captured_envelopes(&self) -> CapturedEnvelopes {
+        self.inner.lock().unwrap().captured_envelopes.clone()
+    }
+
+    pub fn captured_outcomes(&self) -> CapturedOutcomes {
+        self.inner.lock().unwrap().captured_outcomes.clone()
+    }
+
+    fn _take_n_envelopes<const N: usize>(&self) -> [RawEnvelope; N] {
+        let envelopes = self.captured_envelopes().get_envelopes();
+        assert_eq!(envelopes.len(), N);
+
+        envelopes.try_into().unwrap()
+    }
+
+    pub fn add_sampling_rule(self, rule: SamplingRule) -> Self {
+        let mut inner = self.inner.lock().unwrap();
+        assert_eq!(inner.project_configs.len(), 1);
+        let project_config = inner.project_configs.values_mut().next().unwrap();
+
+        if let Some(ErrorBoundary::Ok(sam)) = project_config.config.sampling.as_mut() {
+            sam.rules.push(rule);
+        } else {
+            // Directly modifying the original Option in project_config.config.sampling
+            project_config.config.sampling = Some(ErrorBoundary::Ok({
+                let mut new_sampling_config = SamplingConfig::new();
+                new_sampling_config.rules.push(rule);
+                new_sampling_config
+            }));
+        }
+        drop(inner);
+
+        self
+    }
+
+    pub fn add_basic_project_state(self) -> Self {
+        self.inner
+            .lock()
+            .unwrap()
+            .add_project_state(StateBuilder::new().build());
+        self
+    }
+
+    pub fn add_project_state(self, project_state: impl Into<ProjectState>) -> Self {
+        self.inner
+            .lock()
+            .unwrap()
+            .add_project_state(project_state.into());
+        self
+    }
+
+    /// Returns the public key of the '42' project.
+    pub fn public_key(&self) -> ProjectKey {
+        self.inner
+            .lock()
+            .unwrap()
+            .project_configs
+            .get(&ProjectId::new(42))
+            .as_ref()
+            .unwrap()
+            .public_keys[0]
+            .clone()
+            .public_key
+    }
+
+    pub fn get_dsn_public_key_configs(&self, project_id: ProjectId) -> Option<PublicKeyConfig> {
+        let binding = self.inner.lock().unwrap();
+        let x = binding.project_configs.get(&project_id)?;
+        x.public_keys[0].clone().into()
+    }
+
+    pub fn new() -> Self {
+        let port = random_port();
+        let addr = SocketAddr::from(([127, 0, 0, 1], port));
+
+        // Initialize your mini_sentry state here
+        let mini_sentry = Arc::new(Mutex::new(MiniSentryInner {
+            server_address: addr,
+            captured_envelopes: Default::default(),
+            captured_outcomes: Default::default(),
+            known_relays: HashMap::new(),
+            server_handle: None,
+            runtime: Runtime::new().unwrap(),
+            project_configs: HashMap::new(),
+            global_config: Default::default(),
+        }));
+
+        let mini_sentry = Self { inner: mini_sentry };
+
+        let envelope_handler = make_handle_envelope(mini_sentry.inner.clone());
+        let config_handler = make_handle_project_config(mini_sentry.inner.clone());
+        let outcome_handler = make_handle_outcomes(mini_sentry.inner.clone());
+        let public_key_handler = make_handle_public_keys(mini_sentry.inner.clone());
+        let challenge_handler = make_handle_register_challenge(mini_sentry.inner.clone());
+
+        let router = Router::new()
+            .route("/", get(handler))
+            .route("/api/0/relays/live/", get(is_live))
+            .route("/api/42/envelope/", post(envelope_handler))
+            .route("/api/0/relays/register/challenge/", post(challenge_handler))
+            .route(
+                "/api/0/relays/register/response/",
+                post(|| async { Json(register_response()) }),
+            )
+            .route("/api/0/relays/outcomes/", post(outcome_handler))
+            .route("/api/0/relays/publickeys/", post(public_key_handler))
+            .route("/api/0/relays/projectconfigs/", post(config_handler));
+
+        println!("Listening on {}", addr);
+
+        // Use the runtime inside MiniSentry to spawn the server task
+        let server_handle = mini_sentry.inner.lock().unwrap().runtime.spawn(async move {
+            axum::Server::bind(&addr)
+                .serve(router.into_make_service())
+                .await
+                .unwrap();
+        });
+
+        mini_sentry.inner.lock().unwrap().server_handle = Some(server_handle);
+
+        mini_sentry
+    }
+}
+
+fn decompress(data: &[u8]) -> Result<Vec<u8>, std::io::Error> {
+    let mut decoder = GzDecoder::new(data);
+    let mut decompressed_data = Vec::new();
+    decoder.read_to_end(&mut decompressed_data)?;
+    Ok(decompressed_data)
+}
+
+fn make_handle_outcomes(
+    mini_sentry: Arc<Mutex<MiniSentryInner>>,
+) -> impl Fn(Bytes) -> Pin<Box<dyn Future<Output = Json<&'static str>> + Send>> + Clone {
+    move |bytes| {
+        let mini_sentry = mini_sentry.clone();
+
+        Box::pin(async move {
+            let outcomes: Vec<TrackRawOutcome> = serde_json::from_slice::<Value>(&bytes)
+                .unwrap()
+                .get("outcomes")
+                .unwrap()
+                .as_array()
+                .unwrap()
+                .iter()
+                .map(|val| serde_json::from_value(val.clone()).unwrap())
+                .collect();
+
+            mini_sentry
+                .lock()
+                .unwrap()
+                .captured_outcomes
+                .extend(outcomes);
+
+            Json("ok")
+        })
+    }
+}
+
+fn make_handle_public_keys(
+    mini_sentry: Arc<Mutex<MiniSentryInner>>,
+) -> impl Fn(Bytes) -> Pin<Box<dyn Future<Output = Json<GetRelaysResponse>> + Send>> + Clone {
+    move |bytes| {
+        let mini_sentry = mini_sentry.clone();
+
+        Box::pin(async move {
+            let x = serde_json::from_slice::<Value>(&bytes).unwrap();
+
+            let mut keys = HashMap::new();
+            let mut relays = HashMap::new();
+
+            for id in x
+                .as_object()
+                .unwrap()
+                .get("relay_ids")
+                .unwrap()
+                .as_array()
+                .unwrap()
+            {
+                let relay_id: RelayId = id.as_str().unwrap().parse().unwrap();
+                let guard = mini_sentry.lock().unwrap();
+                if let Some(relay) = guard.known_relays.get(&relay_id).cloned() {
+                    keys.insert(relay_id, Some(relay.public_key.clone()));
+                    relays.insert(relay_id, Some(relay));
+                }
+            }
+
+            let x = GetRelaysResponse { relays };
+
+            Json(x)
+        })
+    }
+}
+
+use relay_server::services::relays::GetRelaysResponse;
+
+fn make_handle_project_config(
+    mini_sentry: Arc<Mutex<MiniSentryInner>>,
+) -> impl Fn(Bytes) -> Pin<Box<dyn Future<Output = Json<ProjectResponse>> + Send>> + Clone {
+    move |_bytes| {
+        let mini_sentry = mini_sentry.clone();
+
+        Box::pin(async move {
+            let mut configs = HashMap::new();
+
+            for project_state in mini_sentry.lock().unwrap().project_configs.values() {
+                let key = project_state.public_keys[0].public_key;
+                configs.insert(key, ErrorBoundary::Ok(Some(project_state.clone())));
+            }
+
+            let global = Some(mini_sentry.lock().unwrap().global_config.clone());
+
+            let response = ProjectResponse {
+                configs,
+                pending: vec![],
+                global,
+            };
+            Json(response)
+        })
+    }
+}
+
+fn make_handle_envelope(
+    mini_sentry: Arc<Mutex<MiniSentryInner>>,
+) -> impl Fn(Bytes) -> Pin<Box<dyn Future<Output = Json<&'static str>> + Send>> + Clone {
+    move |bytes| {
+        let mini_sentry = mini_sentry.clone();
+        Box::pin(async move {
+            let decompressed = decompress(&bytes).unwrap_or(bytes.to_vec());
+            let envelope: RelayEnvelope = *RelayEnvelope::parse_bytes(decompressed.into()).unwrap();
+            let envelope = RawEnvelope::from_envelope(&envelope);
+            mini_sentry
+                .lock()
+                .unwrap()
+                .captured_envelopes
+                .push(envelope);
+
+            Json("ok")
+        })
+    }
+}
+
+async fn handler() -> &'static str {
+    "Hello, mini_sentry!"
+}
+
+fn register_response() -> Value {
+    let relay_id = Uuid::new_v4();
+    let token = SignedRegisterState("abc".into());
+    let version = RelayVersion::current();
+
+    json!({
+        "relay_id": relay_id,
+        "token": token,
+        "version": version,
+    })
+}
+
+fn make_handle_register_challenge(
+    mini_sentry: Arc<Mutex<MiniSentryInner>>,
+) -> impl Fn(Bytes) -> Pin<Box<dyn Future<Output = Json<Value>> + Send>> + Clone {
+    move |bytes| {
+        let mini_sentry = mini_sentry.clone();
+
+        Box::pin(async move {
+            let x = serde_json::from_slice::<Value>(&bytes).unwrap();
+
+            let relay_id: RelayId = x
+                .as_object()
+                .unwrap()
+                .get("relay_id")
+                .unwrap()
+                .as_str()
+                .unwrap()
+                .parse()
+                .unwrap();
+
+            let public_key: PublicKey = x
+                .as_object()
+                .unwrap()
+                .get("public_key")
+                .unwrap()
+                .as_str()
+                .unwrap()
+                .parse()
+                .unwrap();
+
+            let relay_info = RelayInfo {
+                public_key,
+                internal: true,
+            };
+            mini_sentry
+                .lock()
+                .unwrap()
+                .known_relays
+                .insert(relay_id, relay_info);
+
+            Json(json! ({
+                "relay_id": relay_id,
+                "token": SignedRegisterState("123 foobar".into()),
+            }))
+        })
+    }
+}
+
+async fn is_live() -> &'static str {
+    "is_healthy: true"
+}
diff --git a/relay-test/src/relay.rs b/relay-test/src/relay.rs
new file mode 100644
index 000000000..8a5f881e2
--- /dev/null
+++ b/relay-test/src/relay.rs
@@ -0,0 +1,379 @@
+use std::net::SocketAddr;
+use std::path::{Path, PathBuf};
+use std::sync::{Arc, PoisonError};
+
+use hyper::http::HeaderName;
+use std::time::Duration;
+
+use axum::http::HeaderMap;
+use relay_auth::{PublicKey, RelayVersion, SecretKey};
+use relay_base_schema::project::{ProjectId, ProjectKey};
+use relay_config::Config;
+use relay_config::Credentials;
+use relay_config::RelayInfo;
+use reqwest::{self, Response};
+use serde_json::{json, Value};
+use std::env;
+use std::fs::{self, File};
+use std::io::Write;
+use std::os::unix::fs::PermissionsExt;
+use tokio::runtime::Runtime;
+use uuid::Uuid;
+
+//use crate::consumers::processing_config;
+use crate::mini_sentry::MiniSentry;
+use crate::{
+    merge, outcomes_enabled_config, processing_config, random_port, BackgroundProcess, RawEnvelope,
+    TempDir,
+};
+
+pub trait Upstream {
+    fn url(&self) -> String;
+    fn internal_error_dsn(&self) -> String;
+    fn insert_known_relay(&self, relay_id: Uuid, public_key: PublicKey);
+    fn public_dsn_key(&self, id: ProjectId) -> ProjectKey;
+}
+
+impl<U: Upstream> Upstream for Relay<'_, U> {
+    fn url(&self) -> String {
+        self.url()
+    }
+
+    fn internal_error_dsn(&self) -> String {
+        self.upstream_dsn.clone()
+    }
+
+    fn insert_known_relay(&self, relay_id: Uuid, public_key: PublicKey) {
+        self.upstream.insert_known_relay(relay_id, public_key);
+    }
+
+    fn public_dsn_key(&self, id: ProjectId) -> ProjectKey {
+        self.upstream.public_dsn_key(id)
+    }
+}
+
+impl Upstream for MiniSentry {
+    fn url(&self) -> String {
+        self.inner.lock().unwrap().url()
+    }
+
+    fn internal_error_dsn(&self) -> String {
+        self.inner
+            .lock()
+            .unwrap_or_else(PoisonError::into_inner)
+            .internal_error_dsn()
+    }
+
+    fn insert_known_relay(&self, relay_id: Uuid, public_key: PublicKey) {
+        self.inner.lock().unwrap().known_relays.insert(
+            relay_id,
+            RelayInfo {
+                public_key,
+                internal: true,
+            },
+        );
+    }
+
+    fn public_dsn_key(&self, id: ProjectId) -> ProjectKey {
+        self.get_dsn_public_key_configs(id).unwrap().public_key
+    }
+}
+
+fn default_opts(url: String, internal_error_dsn: String, port: u16, host: String) -> Value {
+    json!({
+        "relay": {
+            "upstream": url,
+            "host": host,
+            "port": port,
+            "tls_port": null,
+            "tls_private_key": null,
+            "tls_cert": null,
+        },
+        "sentry": {
+            "dsn": internal_error_dsn,
+            "enabled": true,
+        },
+        "limits": {
+            "max_api_file_upload_size": "1MiB",
+        },
+        "cache": {
+            "batch_interval": 0,
+        },
+        "logging": {
+            "level": "trace",
+        },
+        "http": {
+            "timeout": 3,
+        },
+        "processing": {
+            "enabled": false,
+            "kafka_config": [],
+            "redis": "",
+        },
+        "outcomes": {
+            "aggregator": {
+                "bucket_interval": 1,
+                "flush_interval": 0,
+            },
+        },
+    })
+}
+
+pub struct RelayBuilder<'a, U: Upstream> {
+    pub config: serde_json::Value,
+    mini_version: Option<RelayVersion>,
+    upstream: &'a U,
+}
+
+impl<'a, U: Upstream> RelayBuilder<'a, U> {
+    pub fn enable_processing(mut self) -> Self {
+        let proc = processing_config();
+
+        self.config = merge(self.config, proc, vec![]);
+        self
+    }
+
+    pub fn set_min_version(mut self, version: RelayVersion) -> Self {
+        self.mini_version = Some(version);
+        self
+    }
+
+    pub fn set_accept_unknown_items(mut self, val: bool) -> Self {
+        let val = json!({
+            "routing": {
+                "accept_unknown_items": val,
+            }
+        });
+
+        self.config = merge(self.config, val, vec![]);
+        self
+    }
+
+    pub fn merge_config(mut self, value: serde_json::Value) -> Self {
+        self.config = merge(self.config, value, vec![]);
+        self
+    }
+
+    pub fn enable_outcomes(mut self) -> Self {
+        self.config = merge(self.config, outcomes_enabled_config(), vec![]);
+        self
+    }
+
+    pub fn build(self) -> Relay<'a, U> {
+        let config = Config::from_json_value(self.config).unwrap();
+        let relay_bin = get_relay_binary().unwrap();
+
+        let mut dir = TempDir::default();
+        let dir = dir.create("relay");
+
+        let credentials = load_credentials(&config, &dir);
+
+        self.upstream
+            .insert_known_relay(credentials.id, credentials.public_key);
+
+        let process = BackgroundProcess::new(
+            relay_bin.as_path().to_str().unwrap(),
+            &["-c", dir.as_path().to_str().unwrap(), "run"],
+        );
+
+        let server_address = config.listen_addr();
+
+        // We need this delay before we start sending to relay.
+        std::thread::sleep(Duration::from_millis(500));
+
+        Relay {
+            _process: process,
+            _relay_id: credentials.id,
+            _secret_key: credentials.secret_key,
+            server_address,
+            _health_check_passed: true,
+            _config: Arc::new(config),
+            _client: reqwest::Client::new(),
+            upstream_dsn: self.upstream.internal_error_dsn(),
+            upstream: self.upstream,
+        }
+    }
+}
+
+pub struct Relay<'a, U: Upstream> {
+    server_address: SocketAddr,
+    _process: BackgroundProcess,
+    _relay_id: Uuid,
+    _secret_key: SecretKey,
+    _health_check_passed: bool,
+    _config: Arc<Config>,
+    _client: reqwest::Client,
+    upstream_dsn: String,
+    upstream: &'a U,
+}
+
+impl<'a, U: Upstream> Relay<'a, U> {
+    pub fn server_address(&self) -> SocketAddr {
+        self.server_address
+    }
+
+    pub fn get_dsn(&self, public_key: ProjectKey) -> String {
+        let x = self.server_address();
+        let host = x.ip();
+        let port = x.port();
+
+        format!("http://{public_key}:@{host}:{port}/42")
+    }
+
+    pub fn new(upstream: &'a U) -> Relay<'a, U> {
+        Self::builder(upstream).build()
+    }
+
+    pub fn builder(upstream: &U) -> RelayBuilder<U> {
+        let host = "127.0.0.1".into();
+        let port = random_port();
+        let url = upstream.url();
+        let internal_error_dsn = upstream.internal_error_dsn();
+
+        let config = default_opts(url, internal_error_dsn, port, host);
+
+        RelayBuilder {
+            config,
+            upstream,
+            mini_version: None,
+        }
+    }
+
+    fn url(&self) -> String {
+        format!(
+            "http://{}:{}",
+            self.server_address.ip(),
+            self.server_address.port()
+        )
+    }
+
+    pub fn get_auth_header(&self, dsn_key: ProjectKey) -> String {
+        format!(
+            "Sentry sentry_version=5, sentry_timestamp=1535376240291, sentry_client=rust-node/2.6.3, sentry_key={}",
+            dsn_key
+        )
+    }
+
+    pub fn envelope_url(&self, project_id: ProjectId) -> String {
+        let endpoint = format!("/api/{}/envelope/", project_id);
+        format!("{}{}", self.url(), endpoint)
+    }
+
+    pub fn send_envelope_to_url(&self, envelope: RawEnvelope, url: &str) -> Response {
+        use reqwest::header::HeaderValue;
+
+        let mut headers = HeaderMap::new();
+        headers.insert(
+            "Content-Type",
+            HeaderValue::from_static("application/x-sentry-envelope"),
+        );
+
+        let dsn_key = self.public_dsn_key(envelope.project_id);
+        headers.insert(
+            "X-Sentry-Auth",
+            HeaderValue::from_str(&self.get_auth_header(dsn_key)).unwrap(),
+        );
+
+        let data = envelope.serialize();
+
+        // Add additional headers from envelope if necessary
+        for (key, value) in envelope.http_headers.iter() {
+            headers.insert(
+                HeaderName::from_bytes(key.as_bytes()).unwrap(),
+                HeaderValue::from_str(value).unwrap(),
+            );
+        }
+
+        Runtime::new().unwrap().block_on(async {
+            reqwest::Client::new()
+                .post(url)
+                .headers(headers)
+                .body(data)
+                .send()
+                .await
+                .unwrap()
+        })
+    }
+
+    pub fn send_envelope(&self, envelope: RawEnvelope) {
+        let url = self.envelope_url(envelope.project_id);
+        self.send_envelope_to_url(envelope, &url);
+    }
+}
+
+fn get_relay_binary() -> Result<PathBuf, Box<dyn std::error::Error>> {
+    let version = "latest";
+    if version == "latest" {
+        return Ok(std::env::var("RELAY_BIN")
+            .map_or_else(|_| "../target/debug/relay".into(), PathBuf::from)
+            .canonicalize()
+            .expect("Failed to get absolute path"));
+    };
+
+    let filename = match env::consts::OS {
+        "linux" => "relay-Linux-x86_64",
+        "macos" => "relay-Darwin-x86_64",
+        "windows" => "relay-Windows-x86_64.exe",
+        _ => panic!("Unsupported OS"),
+    };
+
+    let download_path = PathBuf::from(format!(
+        "target/relay_releases_cache/{}_{}",
+        filename, version
+    ));
+
+    if !Path::new(&download_path).exists() {
+        let download_url = format!(
+            "https://github.com/getsentry/relay/releases/download/{}/{}",
+            version, filename
+        );
+
+        let client = reqwest::blocking::Client::new();
+        let mut request = client.get(download_url);
+
+        if let Ok(token) = env::var("GITHUB_TOKEN") {
+            request = request.bearer_auth(token);
+        }
+
+        let response = request.send()?.error_for_status()?;
+
+        // Adjusted part: Read the entire response body at once.
+        let content = response.bytes()?;
+
+        fs::create_dir_all(Path::new(&download_path).parent().unwrap())?;
+        let mut file = File::create(&download_path)?;
+
+        // Write the entire content to the file.
+        file.write_all(&content)?;
+
+        let mut perms = fs::metadata(&download_path)?.permissions();
+        perms.set_mode(0o700); // UNIX-specific; for Windows, you'll need a different approach
+        fs::set_permissions(&download_path, perms)?;
+    }
+
+    Ok(download_path)
+}
+
+fn load_credentials(config: &Config, relay_dir: &Path) -> Credentials {
+    let relay_bin = get_relay_binary().unwrap();
+    let config_path = relay_dir.join("config.yml");
+
+    std::fs::write(config_path.as_path(), config.to_yaml_string().unwrap()).unwrap();
+
+    let output = std::process::Command::new(relay_bin.as_path())
+        .arg("-c")
+        .arg(config_path.parent().unwrap())
+        .arg("credentials")
+        .arg("generate")
+        .output()
+        .unwrap();
+
+    if !output.status.success() {
+        dbg!(&output);
+        panic!("Command execution failed");
+    }
+    let credentials_path = relay_dir.join("credentials.json");
+
+    let credentials_str = std::fs::read_to_string(credentials_path).unwrap();
+    serde_json::from_str(&credentials_str).expect("Failed to parse JSON")
+}
diff --git a/relay/Cargo.toml b/relay/Cargo.toml
index dd10a2d4d..10e263ca0 100644
--- a/relay/Cargo.toml
+++ b/relay/Cargo.toml
@@ -31,3 +31,14 @@ uuid = { workspace = true }
 
 [target.'cfg(target_os = "linux")'.dependencies]
 tikv-jemallocator = { version = "0.5.0", features = ["background_threads"] }
+
+
+[dev-dependencies]
+relay-test = { path = "../relay-test" }
+relay-event-schema = { path = "../relay-event-schema" }
+relay-base-schema = { path = "../relay-base-schema" }
+serde_json = { workspace = true }
+relay-sampling = { path = "../relay-sampling" }
+
+
+
diff --git a/relay/tests/test_dynamic_sampling.rs b/relay/tests/test_dynamic_sampling.rs
new file mode 100644
index 000000000..587621776
--- /dev/null
+++ b/relay/tests/test_dynamic_sampling.rs
@@ -0,0 +1,336 @@
+use relay_base_schema::project::ProjectId;
+use relay_event_schema::protocol::EventId;
+use relay_sampling::config::RuleType;
+use relay_server::envelope::ItemType;
+use relay_server::services::outcome::OutcomeId;
+use relay_test::mini_sentry::MiniSentry;
+use relay_test::relay::Relay;
+use serde_json::json;
+use uuid::Uuid;
+
+use relay_test::{
+    create_error_item, new_sampling_rule, opt_create_transaction_item, x_create_transaction_item,
+    RawEnvelope, StateBuilder,
+};
+
+/// Tests that when sampling is set to 0% for the trace context project the events are removed.
+#[test]
+fn test_it_removes_events() {
+    let sample_rate = 0.0;
+    let project_state = StateBuilder::new()
+        // add a sampling rule to project config that removes all transactions (sample_rate=0)
+        .add_basic_sampling_rule(RuleType::Transaction, sample_rate)
+        .set_transaction_metrics_version(1);
+
+    let public_key = project_state.public_key();
+    let sentry = MiniSentry::new().add_project_state(project_state);
+    let relay = Relay::builder(&sentry).enable_outcomes().build();
+
+    // create an envelope with a trace context that is initiated by this project (for simplicity)
+    let envelope = RawEnvelope::new().add_transaction_and_trace_info(public_key, None);
+
+    // send the event, the transaction should be removed.
+    relay.send_envelope(envelope);
+
+    // the event should be removed by Relay sampling
+    sentry.captured_envelopes().wait(2).assert_empty();
+
+    sentry
+        .captured_outcomes()
+        .wait_for_outcome(30)
+        .assert_outcome_qty(1)
+        .assert_all_outcome_id(OutcomeId::FILTERED)
+        .assert_all_outcome_reasons("Sampled:1");
+}
+
+///Tests that we keep an event if it is of type error.
+#[test]
+fn test_it_does_not_sample_error() {
+    let project_state = StateBuilder::new()
+        // add a sampling rule to project config that removes all traces of release "1.0"
+        .add_sampling_rule(new_sampling_rule(
+            0.0,
+            RuleType::Trace.into(),
+            vec![1.0],
+            None,
+            None,
+        ))
+        .set_transaction_metrics_version(1);
+    let public_key = project_state.public_key();
+
+    let sentry = MiniSentry::new().add_project_state(project_state);
+    let relay = Relay::builder(&sentry).enable_outcomes().build();
+
+    let (item, trace_id, event_id) = create_error_item();
+
+    // create an envelope with a trace context that is initiated by this project (for simplicity)
+    let envelope = RawEnvelope::new()
+        .add_raw_item(item)
+        .add_header("event_id", event_id.to_string().as_str())
+        .add_trace_info(
+            trace_id,
+            public_key,
+            Some(1.0),
+            Some(true),
+            Some(1.0),
+            Some("/transaction"),
+        );
+
+    // send the event, the transaction should be removed.
+    relay.send_envelope(envelope);
+
+    // test that error is kept by Relay
+    sentry
+        .captured_envelopes()
+        .wait_for_envelope(5)
+        .assert_item_qty(1)
+        // double check that we get back our object
+        .assert_contains_event_id(EventId(event_id));
+}
+
+// Tests that it tags an incoming error if the trace connected to it its sampled or not.
+#[test]
+fn test_it_tags_error() {
+    for (sample_rate, expected_sampled) in [(1.0, true), (0.0, false)] {
+        // add a sampling rule to project config that keeps all events (sample_rate=1)
+        let project_state =
+            StateBuilder::new().add_basic_sampling_rule(RuleType::Trace, sample_rate);
+        let public_key = project_state.public_key();
+
+        let sentry = MiniSentry::new().add_project_state(project_state);
+
+        // create an envelope with a trace context that is initiated by this project (for simplicity)
+        let envelope = RawEnvelope::new().add_error_event_with_trace_info(public_key);
+        let relay = Relay::builder(&sentry).enable_outcomes().build();
+        relay.send_envelope(envelope);
+
+        sentry
+            .captured_envelopes()
+            .wait_for_envelope(3)
+            .assert_envelope_qty(1)
+            .assert_all_sampled_status(expected_sampled);
+    }
+}
+
+///Tests that when sampling is set to 100% for the trace context project the events are kept
+#[test]
+fn test_it_keeps_event() {
+    let rule = new_sampling_rule(1.0, RuleType::Transaction.into(), vec![1.0], None, None);
+
+    let project_state = StateBuilder::new().add_sampling_rule(rule);
+    let public_key = project_state.public_key();
+
+    let sentry = MiniSentry::new().add_project_state(project_state);
+
+    let relay = Relay::builder(&sentry).enable_outcomes().build();
+
+    let (item, trace_id, event_id) = x_create_transaction_item(None);
+
+    let envelope = RawEnvelope::new()
+        .add_raw_item(item)
+        .set_event_id(event_id)
+        .add_trace_info_simple(trace_id, public_key);
+
+    relay.send_envelope(envelope);
+
+    sentry
+        .captured_envelopes()
+        .wait_for_envelope(3)
+        .assert_item_qty(1)
+        .assert_contains_event_id(EventId(event_id));
+}
+
+/// Tests that the `public_key` from the trace context is used.
+///
+/// The project configuration corresponding to the project pointed to
+/// by the context `public_key` DSN is used (not the DSN of the request).
+///
+/// # Scenario
+///
+/// - Create a trace context for `projectA` and send an event from `projectB`
+///   using `projectA`'s trace.
+/// - Configure `project1` to sample out all events (`sample_rate=0`).
+/// - Configure `project2` to sample in all events (`sample_rate=1`).
+///
+/// # Steps
+///
+/// 1. Send an event to `project2` with a trace from `project1`.
+///    - It should be removed (sampled out).
+/// 2. Send an event to `project1` with a trace from `project2`.
+///    - It should pass through.
+///
+/// This test ensures that the sampling decision respects the trace context's
+/// `public_key` rather than the request's `public_key`.
+#[test]
+fn test_uses_trace_public_key() {
+    // create basic project configs
+    let project_id1 = ProjectId::new(42);
+    let config1 = StateBuilder::new()
+        .set_project_id(project_id1)
+        .set_transaction_metrics_version(1)
+        .set_sampling_rule(0.0, RuleType::Trace);
+    let public_key1 = config1.public_key();
+
+    let project_id2 = ProjectId::new(43);
+    let config2 = StateBuilder::new()
+        .set_project_id(project_id2)
+        .set_transaction_metrics_version(1)
+        .set_sampling_rule(1.0, RuleType::Trace);
+    let public_key2 = config2.public_key();
+
+    let sentry = MiniSentry::new()
+        .add_project_state(config1)
+        .add_project_state(config2);
+    let relay = Relay::builder(&sentry).enable_outcomes().build();
+
+    // First
+    // send trace with project_id1 context (should be removed)
+    let (transaction, trace_id, _) = x_create_transaction_item(None);
+    let envelope = RawEnvelope::new()
+        .add_raw_item(transaction)
+        .add_trace_info_simple(trace_id, public_key1)
+        .set_project_id(project_id2);
+
+    // Send the event, the transaction should be removed.
+    relay.send_envelope(envelope);
+    // The event should be removed by Relay sampling.
+    sentry.captured_envelopes().wait(1).assert_empty();
+
+    // and it should create an outcome
+    sentry.captured_outcomes().assert_outcome_qty(1).clear();
+
+    // Second
+    // send trace with project_id2 context (shoudl go through)
+    let (transaction, trace_id, _) = x_create_transaction_item(None);
+    let envelope = RawEnvelope::new()
+        .add_raw_item(transaction)
+        .add_trace_info_simple(trace_id, public_key2)
+        .set_project_id(project_id1);
+
+    // send the event
+    relay.send_envelope(envelope);
+
+    // the event should be passed along to usptream (with the transaction unchanged)
+    sentry
+        .captured_envelopes()
+        .wait_for_envelope(10)
+        .assert_item_qty(1)
+        .assert_all_item_types(ItemType::Transaction);
+
+    // no outcome should be generated (since the event is passed along to the upstream)
+    sentry.captured_outcomes().assert_empty();
+}
+
+/// Associated items are removed together with event item.
+///
+/// The event is sent twice to account for both fast and slow paths.
+///
+/// When sampling decides to remove a transaction it should also remove all
+/// dependent items (attachments).
+#[test]
+fn test_multi_item_envelope() {
+    for rule_type in [RuleType::Transaction, RuleType::Trace] {
+        let project_id = ProjectId::new(42);
+        let project_state = StateBuilder::new()
+            .enable_outcomes()
+            .set_project_id(project_id)
+            .set_transaction_metrics_version(1)
+            .add_basic_sampling_rule(rule_type, 0.0);
+        let public_key = project_state.public_key();
+        let sentry = MiniSentry::new().add_project_state(project_state.clone());
+        let relay = Relay::builder(&sentry).enable_outcomes().build();
+
+        for _ in 0..2 {
+            let envelope = RawEnvelope::new()
+                .add_transaction_and_trace_info(public_key, None)
+                .add_item_from_json(json!({"x": "some attachment"}), ItemType::Attachment)
+                .add_item_from_json(json!({"y": "some other attachment"}), ItemType::Attachment);
+
+            relay.send_envelope(envelope);
+
+            sentry.captured_envelopes().wait(1).assert_empty().clear();
+
+            sentry.captured_outcomes().wait_for_outcome(2).clear();
+        }
+    }
+}
+
+/// Tests that the client sample rate is honored when applying server-side
+/// sampling. Do so by sending an envelope with a very low reported client sample rate
+/// and a sampling rule with the same sample rate. The server should adjust
+/// itself to 1.0. The chances of this test passing without the adjustment in
+/// place are very low (but not 0).
+#[test]
+fn test_client_sample_rate_adjusted() {
+    let sample_rate = 0.001;
+
+    for rule_type in [RuleType::Trace, RuleType::Transaction] {
+        let project_state = StateBuilder::new()
+            .set_transaction_metrics_version(1)
+            .add_basic_sampling_rule(rule_type, sample_rate);
+        let public_key = project_state.public_key();
+        let sentry = MiniSentry::new().add_project_state(project_state);
+        let relay = Relay::builder(&sentry).build();
+
+        let envelope = RawEnvelope::new().add_transaction_and_trace_info_not_simple(
+            public_key,
+            None,
+            Some(sample_rate),
+        );
+
+        relay.send_envelope(envelope);
+
+        sentry
+            .captured_envelopes()
+            .wait_for_envelope(5)
+            .debug()
+            .assert_item_qty(1)
+            .assert_n_item_types(ItemType::ClientReport, 1)
+            .clear();
+
+        let envelope = RawEnvelope::new().add_transaction_and_trace_info_not_simple(
+            public_key,
+            None,
+            Some(1.0),
+        );
+
+        relay.send_envelope(envelope);
+        sentry
+            .captured_envelopes()
+            .wait(1)
+            .assert_item_qty(1)
+            .assert_n_item_types(ItemType::ClientReport, 1);
+    }
+}
+
+///  Tests that nested relays do not end up double-sampling. This is guaranteed
+///  by the fact that we never actually use an RNG, but hash either the event-
+///  or trace-id.
+#[test]
+fn test_relay_chain() {
+    for rule_type in [RuleType::Transaction, RuleType::Trace] {
+        let sample_rate = 0.001;
+        let project_state = StateBuilder::new().add_basic_sampling_rule(rule_type, sample_rate);
+        let sentry = MiniSentry::new().add_project_state(project_state);
+        let inner_relay = Relay::new(&sentry);
+        let outer_relay = Relay::new(&inner_relay);
+
+        // A trace ID that gets hashed to a value lower than 0.001
+        let magic_uuid = Uuid::parse_str("414e119d37694a32869f9d81b76a0b70").unwrap();
+
+        let (trace_id, event_id) = match rule_type {
+            RuleType::Trace => (Some(magic_uuid), None),
+            RuleType::Transaction => (None, Some(magic_uuid)),
+            RuleType::Unsupported => panic!(),
+        };
+
+        let (item, _, _) = opt_create_transaction_item(None, trace_id, event_id);
+        let envelope = RawEnvelope::new().add_raw_item(item);
+        outer_relay.send_envelope(envelope);
+
+        sentry
+            .captured_envelopes()
+            .wait_for_envelope(2)
+            .assert_n_item_types(ItemType::Transaction, 1);
+    }
+}
diff --git a/tests/integration/test_dynamic_sampling.py b/tests/integration/test_dynamic_sampling.py
index 3b685fe0c..d512593e4 100644
--- a/tests/integration/test_dynamic_sampling.py
+++ b/tests/integration/test_dynamic_sampling.py
@@ -4,7 +4,6 @@ import json
 
 import pytest
 from sentry_sdk.envelope import Envelope, Item, PayloadRef
-import queue
 
 
 def _create_transaction_item(trace_id=None, event_id=None, transaction=None, **kwargs):
@@ -35,50 +34,6 @@ def _create_transaction_item(trace_id=None, event_id=None, transaction=None, **k
     return item, trace_id, event_id
 
 
-def _create_event_item(
-    environment=None, release=None, trace_id=None, event_id=None, transaction=None
-):
-    """
-    Creates an event with the specified environment and release
-    :return: a tuple (event_item, event_id)
-    """
-    event_id = event_id or uuid.uuid4().hex
-    trace_id = trace_id or uuid.uuid4().hex
-    item = {
-        "event_id": event_id,
-        "message": "Hello, World!",
-        "contexts": {
-            "trace": {
-                "trace_id": trace_id,
-                "span_id": "FA90FDEAD5F74052",
-                "type": "trace",
-            }
-        },
-        "extra": {"id": event_id},
-    }
-    if transaction is not None:
-        item["transaction"] = transaction
-    if environment is not None:
-        item["environment"] = environment
-    if release is not None:
-        item["release"] = release
-    return item, trace_id, event_id
-
-
-def _outcomes_enabled_config():
-    """
-    Returns a configuration for Relay that enables outcome generation
-    """
-    return {
-        "outcomes": {
-            "emit_outcomes": True,
-            "batch_size": 1,
-            "batch_interval": 1,
-            "source": "relay",
-        }
-    }
-
-
 def _add_sampling_config(
     config,
     sample_rate,
@@ -176,25 +131,6 @@ def _add_trace_info(
         trace_info["sampled"] = sampled
 
 
-def _create_event_envelope(
-    public_key, client_sample_rate=None, trace_id=None, event_id=None, transaction=None
-):
-    envelope = Envelope()
-    event, trace_id, event_id = _create_event_item(
-        trace_id=trace_id, event_id=event_id, transaction=transaction
-    )
-    envelope.add_event(event)
-    _add_trace_info(
-        envelope,
-        trace_id=trace_id,
-        public_key=public_key,
-        client_sample_rate=client_sample_rate,
-        transaction=transaction,
-    )
-
-    return envelope, trace_id, event_id
-
-
 def _create_transaction_envelope(
     public_key,
     client_sample_rate=None,
@@ -218,346 +154,6 @@ def _create_transaction_envelope(
     return envelope, trace_id, event_id
 
 
-def _create_error_envelope(public_key):
-    envelope = Envelope()
-    event_id = "abbcea72-abc7-4ac6-93d2-2b8f366e58d7"
-    trace_id = "f26fdb98-68f7-4e10-b9bc-2d2dd9256e53"
-    error_event = {
-        "event_id": event_id,
-        "message": "This is an error.",
-        "extra": {"msg_text": "This is an error", "id": event_id},
-        "type": "error",
-        "environment": "production",
-        "release": "foo@1.2.3",
-    }
-    envelope.add_event(error_event)
-    _add_trace_info(
-        envelope,
-        trace_id=trace_id,
-        public_key=public_key,
-        client_sample_rate=1.0,
-        transaction="/transaction",
-        release="1.0",
-        sampled="true",
-    )
-    return envelope, event_id
-
-
-def test_it_removes_events(mini_sentry, relay):
-    """
-    Tests that when sampling is set to 0% for the trace context project the events are removed
-    """
-    project_id = 42
-    relay = relay(mini_sentry, _outcomes_enabled_config())
-
-    # create a basic project config
-    config = mini_sentry.add_basic_project_config(project_id)
-    config["config"]["transactionMetrics"] = {"version": 1}
-
-    public_key = config["publicKeys"][0]["publicKey"]
-
-    # add a sampling rule to project config that removes all transactions (sample_rate=0)
-    rules = _add_sampling_config(config, sample_rate=0, rule_type="transaction")
-
-    # create an envelope with a trace context that is initiated by this project (for simplicity)
-    envelope, trace_id, event_id = _create_transaction_envelope(public_key)
-
-    # send the event, the transaction should be removed.
-    relay.send_envelope(project_id, envelope)
-    # the event should be removed by Relay sampling
-    with pytest.raises(queue.Empty):
-        mini_sentry.captured_events.get(timeout=1)
-
-    outcomes = mini_sentry.captured_outcomes.get(timeout=2)
-    assert outcomes is not None
-    outcome = outcomes["outcomes"][0]
-    assert outcome.get("outcome") == 1
-    assert outcome.get("reason") == f"Sampled:{rules[0]['id']}"
-
-
-def test_it_does_not_sample_error(mini_sentry, relay):
-    """
-    Tests that we keep an event if it is of type error.
-    """
-    project_id = 42
-    relay = relay(mini_sentry, _outcomes_enabled_config())
-
-    # create a basic project config
-    config = mini_sentry.add_basic_project_config(project_id)
-    public_key = config["publicKeys"][0]["publicKey"]
-
-    # add a sampling rule to project config that removes all traces of release "1.0"
-    _add_sampling_config(config, sample_rate=0, rule_type="trace", releases=["1.0"])
-
-    # create an envelope with a trace context that is initiated by this project (for simplicity)
-    envelope, event_id = _create_error_envelope(public_key)
-
-    # send the event, the transaction should be removed.
-    relay.send_envelope(project_id, envelope)
-    # test that error is kept by Relay
-    envelope = mini_sentry.captured_events.get(timeout=1)
-    assert envelope is not None
-    # double check that we get back our object
-    # we put the id in extra since Relay overrides the initial event_id
-    items = [item for item in envelope]
-    assert len(items) == 1
-    evt = items[0].payload.json
-    evt_id = evt.setdefault("extra", {}).get("id")
-    assert evt_id == event_id
-
-
-@pytest.mark.parametrize(
-    "expected_sampled, sample_rate",
-    [
-        (True, 1.0),
-        (False, 0.0),
-    ],
-)
-def test_it_tags_error(mini_sentry, relay, expected_sampled, sample_rate):
-    """
-    Tests that it tags an incoming error if the trace connected to it its sampled or not.
-    """
-    project_id = 42
-    relay = relay(mini_sentry, _outcomes_enabled_config())
-
-    # create a basic project config
-    config = mini_sentry.add_basic_project_config(project_id)
-    public_key = config["publicKeys"][0]["publicKey"]
-
-    # add a sampling rule to project config that keeps all events (sample_rate=1)
-    _add_sampling_config(
-        config, sample_rate=sample_rate, rule_type="trace", releases=["1.0"]
-    )
-
-    # create an envelope with a trace context that is initiated by this project (for simplicity)
-    envelope, event_id = _create_error_envelope(public_key)
-
-    # send the event, the transaction should be removed.
-    relay.send_envelope(project_id, envelope)
-    # test that error is kept by Relay
-    envelope = mini_sentry.captured_events.get(timeout=1)
-    assert envelope is not None
-    # double check that we get back our object
-    # we put the id in extra since Relay overrides the initial event_id
-    items = [item for item in envelope]
-    assert len(items) == 1
-    evt = items[0].payload.json
-    # we check if it is marked as sampled
-    assert evt["contexts"]["trace"]["sampled"] == expected_sampled
-    evt_id = evt.setdefault("extra", {}).get("id")
-    assert evt_id == event_id
-
-
-def test_it_keeps_events(mini_sentry, relay):
-    """
-    Tests that when sampling is set to 100% for the trace context project the events are kept
-    """
-    project_id = 42
-    relay = relay(mini_sentry, _outcomes_enabled_config())
-
-    # create a basic project config
-    config = mini_sentry.add_basic_project_config(project_id)
-    public_key = config["publicKeys"][0]["publicKey"]
-
-    # add a sampling rule to project config that keeps all events (sample_rate=1)
-    _add_sampling_config(config, sample_rate=1, rule_type="transaction")
-
-    # create an envelope with a trace context that is initiated by this project (for simplicity)
-    envelope, trace_id, event_id = _create_transaction_envelope(public_key)
-
-    # send the event, the transaction should be removed.
-    relay.send_envelope(project_id, envelope)
-    # the event should be left alone by Relay sampling
-    envelope = mini_sentry.captured_events.get(timeout=1)
-    assert envelope is not None
-    # double check that we get back our object
-    # we put the id in extra since Relay overrides the initial event_id
-    items = [item for item in envelope]
-    assert len(items) == 1
-    evt = items[0].payload.json
-    evt_id = evt.setdefault("extra", {}).get("id")
-    assert evt_id == event_id
-
-    # no outcome should be generated since we forward the event to upstream
-    with pytest.raises(queue.Empty):
-        mini_sentry.captured_outcomes.get(timeout=2)
-
-
-def test_uses_trace_public_key(mini_sentry, relay):
-    """
-    Tests that the public_key from the trace context is used
-
-    The project configuration corresponding to the project pointed to
-    by the context public_key DSN is used (not the dsn of the request)
-
-    Create a trace context for projectA and send an event from projectB
-    using projectA's trace.
-
-    Configure project1 to sample out all events (sample_rate=0)
-    Configure project2 to sample in all events (sample_rate=1)
-    First:
-        Send event to project2 with trace from project1
-        It should be removed (sampled out)
-    Second:
-        Send event to project1 with trace from project2
-        It should pass through
-
-    """
-    relay = relay(mini_sentry, _outcomes_enabled_config())
-
-    # create basic project configs
-    project_id1 = 42
-    config1 = mini_sentry.add_basic_project_config(project_id1)
-    config1["config"]["transactionMetrics"] = {"version": 1}
-
-    public_key1 = config1["publicKeys"][0]["publicKey"]
-    _add_sampling_config(config1, sample_rate=0, rule_type="trace")
-
-    project_id2 = 43
-    config2 = mini_sentry.add_basic_project_config(project_id2)
-    config2["config"]["transactionMetrics"] = {"version": 1}
-    public_key2 = config2["publicKeys"][0]["publicKey"]
-    _add_sampling_config(config2, sample_rate=1, rule_type="trace")
-
-    # First
-    # send trace with project_id1 context (should be removed)
-    envelope = Envelope()
-    transaction, trace_id, event_id = _create_transaction_item()
-    envelope.add_transaction(transaction)
-    _add_trace_info(envelope, trace_id=trace_id, public_key=public_key1)
-
-    # send the event, the transaction should be removed.
-    relay.send_envelope(project_id2, envelope)
-    # the event should be removed by Relay sampling
-    with pytest.raises(queue.Empty):
-        mini_sentry.captured_events.get(timeout=1)
-
-    # and it should create an outcome
-    outcomes = mini_sentry.captured_outcomes.get(timeout=2)
-    assert outcomes is not None
-    with pytest.raises(queue.Empty):
-        mini_sentry.captured_outcomes.get(timeout=1)
-
-    # Second
-    # send trace with project_id2 context (should go through)
-    envelope = Envelope()
-    transaction, trace_id, event_id = _create_transaction_item()
-    envelope.add_transaction(transaction)
-    _add_trace_info(envelope, trace_id=trace_id, public_key=public_key2)
-
-    # send the event.
-    relay.send_envelope(project_id1, envelope)
-
-    # the event should be passed along to upstream (with the transaction unchanged)
-    evt = mini_sentry.captured_events.get(timeout=1).get_transaction_event()
-    assert evt is not None
-
-    # no outcome should be generated (since the event is passed along to the upstream)
-    with pytest.raises(queue.Empty):
-        mini_sentry.captured_outcomes.get(timeout=2)
-
-
-@pytest.mark.parametrize(
-    "rule_type, event_factory",
-    [
-        ("transaction", _create_transaction_envelope),
-        ("trace", _create_transaction_envelope),
-    ],
-)
-def test_multi_item_envelope(mini_sentry, relay, rule_type, event_factory):
-    """
-    Associated items are removed together with event item.
-
-    The event is sent twice to account for both fast and slow paths.
-
-    When sampling decides to remove a transaction it should also remove all
-    dependent items (attachments).
-    """
-    project_id = 42
-    relay = relay(mini_sentry, _outcomes_enabled_config())
-
-    # create a basic project config
-    config = mini_sentry.add_basic_project_config(project_id)
-    config["config"]["transactionMetrics"] = {"version": 1}
-    # add a sampling rule to project config that removes all transactions (sample_rate=0)
-    public_key = config["publicKeys"][0]["publicKey"]
-    # add a sampling rule to project config that drops all events (sample_rate=0), it should be ignored
-    # because there is an invalid rule in the configuration
-    _add_sampling_config(config, sample_rate=0, rule_type=rule_type)
-
-    for i in range(2):
-        # create an envelope with a trace context that is initiated by this project (for simplicity)
-        envelope = Envelope()
-        # create an envelope with a trace context that is initiated by this project (for simplicity)
-        envelope, trace_id, event_id = event_factory(public_key)
-        envelope.add_item(
-            Item(payload=PayloadRef(json={"x": "some attachment"}), type="attachment")
-        )
-        envelope.add_item(
-            Item(
-                payload=PayloadRef(json={"y": "some other attachment"}),
-                type="attachment",
-            )
-        )
-
-        # send the event, the transaction should be removed.
-        relay.send_envelope(project_id, envelope)
-        # the event should be removed by Relay sampling
-        with pytest.raises(queue.Empty):
-            mini_sentry.captured_events.get(timeout=1)
-
-        outcomes = mini_sentry.captured_outcomes.get(timeout=2)
-        assert outcomes is not None
-
-
-@pytest.mark.parametrize(
-    "rule_type, event_factory",
-    [
-        ("transaction", _create_transaction_envelope),
-        ("trace", _create_transaction_envelope),
-    ],
-)
-def test_client_sample_rate_adjusted(mini_sentry, relay, rule_type, event_factory):
-    """
-    Tests that the client sample rate is honored when applying server-side
-    sampling. Do so by sending an envelope with a very low reported client sample rate
-    and a sampling rule with the same sample rate. The server should adjust
-    itself to 1.0. The chances of this test passing without the adjustment in
-    place are very low (but not 0).
-    """
-    project_id = 42
-    relay = relay(mini_sentry)
-    config = mini_sentry.add_basic_project_config(project_id)
-    config["config"]["transactionMetrics"] = {"version": 1}
-    public_key = config["publicKeys"][0]["publicKey"]
-
-    # the closer to 0, the less flaky the test is
-    # still needs to be distinguishable from 0 in a f32 in rust
-    SAMPLE_RATE = 0.001
-    _add_sampling_config(config, sample_rate=SAMPLE_RATE, rule_type=rule_type)
-
-    envelope, trace_id, event_id = event_factory(
-        public_key, client_sample_rate=SAMPLE_RATE
-    )
-
-    relay.send_envelope(project_id, envelope)
-
-    received_envelope = mini_sentry.captured_events.get(timeout=1)
-    received_envelope.get_transaction_event()
-
-    envelope, trace_id, event_id = event_factory(public_key, client_sample_rate=1.0)
-
-    relay.send_envelope(project_id, envelope)
-
-    # Relay is sending a client report, skip over it
-    received_envelope = mini_sentry.captured_events.get(timeout=1)
-    assert received_envelope.get_transaction_event() is None
-    assert received_envelope.get_event() is None
-
-    with pytest.raises(queue.Empty):
-        mini_sentry.captured_events.get(timeout=1)
-
-
 @pytest.mark.parametrize(
     "rule_type, event_factory",
     [
